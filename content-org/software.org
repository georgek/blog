#+author: George Kettleborough
#+hugo_draft: t
#+hugo_base_dir: ../
#+hugo_categories: Software

* DONE Emacs Undo Redo                                                :emacs:
CLOSED: [2023-12-14 Thu 22:18]
:PROPERTIES:
:EXPORT_FILE_NAME: emacs-undo
:END:

** Introduction                                                      :ignore:

At first glance, undo seems like a simple thing expected of most software these days and
hardly worth writing about. Indeed, when I say Emacs has a very powerful undo
system---probably more so than any other text editor---you may wonder what could make an
undo system powerful. So let's start by considering two big problems most undo systems
have:

1. If you undo something, make some changes, then change your mind, what you undid is
   now lost and unrecoverable,
2. If you make changes in two parts of the same file you cannot undo changes in the
   first part without undoing changes in the second part too.

Emacs comes with solutions to each of these out of the box. Read on to understand how it
works and how we can improve upon the defaults even more.

** Standard undo system

To deal with the first problem, it's quite simple: Emacs stores undo commands themselves
in the undo history. To understand how this works, imagine a situation where you've made
two changes to a buffer and are now in state ~c~. The history would look like this:

#+begin_example
   a---b---c
           ^
#+end_example

If you now undo twice, you will get back to state ~a~, as you would expect, and the
history will look like this:

#+begin_example
   a---b---c
   ^
#+end_example

So far, so good, but what happens if we now make a non-undoing change such as entering
some new text to get into state ~b'~. In most editors, states ~b~ and ~c~ would at this
point be lost, but in Emacs we get the following history:

#+begin_example
   a---b---c---b---a---b'
                       ^
#+end_example

What's happened is the moment a command breaks the chain of undos, the chain of undos
are themselves added to the undo history before any subsequent changes. This means you
can always get back to /any/ previous state, including ~b~ and ~c~.

This might sound quite hard to understand but, in fact, it's actually quite intuitive
and I used this standard undo system for many years.

** Undo-tree

Another way to understand the states above is as a tree:

#+begin_example
     a
    / \
   b   b'
   |   ^
   c
#+end_example

Now it's perhaps possible to see that Emacs undo is actually doing a kind of tree
traversal but, by default, you can't see the tree, you just have to imagine it.

But what if it's too difficult to imagine? That's where [[https://www.dr-qubit.org/undo-tree.html][undo-tree]] comes in. Undo-tree
replaces the standard undo system with an alternative system that gives the standard
undo/redo commands while still retaining full access to the tree when you need it. It
comes with a graphical tree browser so you can view the undo tree and move anywhere
within it.

I should have installed undo-tree years ago. As it happens, I've only started using it
recently, but now an even better alternative is available.

** Vundo

How I thought undo-tree worked was it used the standard Emacs undo system but merely
enabled easier navigation through undo states by displaying a tree. This isn't right, it
actually replaces the undo system completely, but this /is/ how [[https://github.com/casouri/vundo][vundo]] works. With vundo
you use the standard undo system as described above, but you can display it as a tree
and navigate through it when you need to.

But vundo would not be competitive with undo-tree if it weren't for a couple of recent
changes to the standard Emacs undo system. These are the commands ~undo-only~ and
~undo-redo~. Unlike standard ~undo~, ~undo-only~ will not undo undos and ~undo-redo~
will /only/ undo undos and not record itself as something to be undone. This might sound
a bit confusing, but you can think of ~undo-only~ and ~undo-redo~ as exposing just the
"normal" linear undo that most editors would provide.

I now have the following ~vundo config~:

#+begin_src elisp
(use-package vundo
  :bind (("C-x u" . vundo)
         ("C-/" . undo-only)
         ("C-?" . undo-redo))
  :config
  (setq vundo-glyph-alist vundo-ascii-symbols))
#+end_src

To get persistent undo (ie. saving the undo history across Emacs sessions) there is
[[https://github.com/emacsmirror/undo-fu-session][undo-fu-session]].

With this setup you get what undo-tree provided: the simple undo/redo system most of the
time and access to the full tree when you need it. But because it uses the standard
Emacs undo system it is simpler, potentially more robust and you get to use one of the
most powerful Emacs undo features of all, as we will see next.

** Undo in region

We've now covered problem number 1, but what about 2? A tragically little-known feature
of the Emacs undo system is undo in region. Quite simply, if you select a region and
undo, it will undo only within that region! How cool is that?

Undo-tree does support this, but it must be enabled by setting
~undo-tree-enable-undo-in-region~. However, it is known to be buggy and the undo-tree
author recommends against its use. But if we use vundo we can use it just fine.

** Conclusion

The default Emacs undo system is the best there is. It's one of the many small things
that mean Emacs users never want to leave Emacs. Not only does it let you recover any
previous state, you can even restrict your undoing to portions of the whole buffer.

But it wouldn't really be Emacs if we didn't still try to improve things. With just a
couple of tweaks and a couple of extra packages we get an undo system that is easy to
understand while losing none of its power and fully persistent between Emacs sessions.

Happy hacking!

* DONE Bash History Hacks                                 :bash:linux:direnv:
CLOSED: [2023-12-05 Tue 22:22]
:PROPERTIES:
:EXPORT_FILE_NAME: project-local-bash-history
:END:

** Introduction                                                      :ignore:

When you work a lot on the command line, history can be invaluable. I've lost count of
the number of times I've forgotten how I ran some earlier command and used my bash
history to find out what it was. This is one of the big advantages of using CLIs over
GUIs.

** Accessing history

The main interface I use to my history is ~^P~ (~Ctrl-P~). This recalls the previous
command from history. Subsequent presses step further back and ~^N~ steps forward
again. These keys are set in muscle memory at this point, I use them that much (they
also work in emacs and many other places).

A really useful extension to that is ~^R~. This does a reverse incremental search
through your history for whatever you type. Subsequent presses of ~^R~ go further
back. I do this many times each day and cringe when I see people stepping up further
than a few ~^P~ through history.

You can also use ~^S~ to search forwards again (so the counterpart to ~^N~), but you
probably need to add the following option in your ~.bashrc~ first:[fn:7]

#+begin_src bash
stty -ixon
#+end_src

Then there is searching through history with something like ~history | grep <cmd>~ but
sometimes I just do ~history~ and have a look around. You could, of course, pipe your
history anywhere else like into ~sed~ and ~uniq~ to perform some kind of stats on your
history.

I like to set the following to enable a nicer timestamp when viewing history:

#+begin_src bash
HISTTIMEFORMAT="[%F %T] "
#+end_src

Now let's look at some tweaks to help with collecting and curating said history.

[fn:7] See: https://unix.stackexchange.com/questions/73498/how-to-cycle-through-reverse-i-search-in-bash

** Unlimited history

The first thing to enable is an unlimited history file. You have the disk space. Put the
following options in your ~.bashrc~ file:

#+begin_src bash
HISTFILESIZE=
HISTSIZE=
shopt -s histappend
#+end_src

You should search any existing ~.bashrc~ file for these options as many distros include
them set by default.

At this point it's useful to understand how bash history works. First there is the
history we were interacting with above via ~^P~ and ~history~ etc. This is stored in
memory and local to each bash instance. When you type new commands, this is where they
end up. Then, separately, there is a persistent history file which is stored on
disk. You can find out where yours will be by checking the variable ~HISTFILE~ (it's
usually something like ~~/.bash_history~).

By default, when you run ~bash~ it truncates your history file to ~HISTFILESIZE~ then
reads it into memory. When you exit it overwrites your history file with ~HISTSIZE~
entries from memory. With these variables unset the limits are removed, but you still
need to enable ~histappend~ so bash /appends/ to the history file instead of overwriting
it. Otherwise you'll get history loss when you run multiple shells.

I also set the following option:

#+begin_src bash
export HISTCONTROL=ignoreboth
#+end_src

This ignores duplicate lines and lines that start with a space, so if you are going to
include a password or something you can start the line with a space to stop it getting
into your history.

** Project-local history

Sometimes when I'm exploring some new data or tools it seems appropriate to keep history
local to that project only. This gives me an informal log of what I've done to get the
data files in my working directory. This can be especially useful if you later need to
formalise things for writing a paper, for example.

What we'd like is when we ~cd~ to a project any in-memory history is written out to the
current/old history file, then switch to a project-specific history file, clear the
in-memory history and read in the project-specific history file.

For this I wondered if I could use [[https://direnv.net/][direnv]] which is a great tool for setting
project-specific environment variables. But unfortunately direnv can /only/ set
environment variables.[fn:6] If we simply set ~HISTFILE~ in the ~.envrc~ file this won't
have the desired effect because, as mentioned above, bash only reads the history file
when it opens and writes it when it exits. We need to also interact with the ~history~
command directly to control writing/reading to the old/new history files.

Fortunately, someone else wondered if they could do this with direnv and posted a
solution to the GitHub issue board using a bash function:
https://github.com/direnv/direnv/issues/1062

I have tweaked the solution slightly and come up with the following:

#+begin_src bash
_set_local_histfile() {
    history -a

    if [[ -n $DIRENV_FILE ]] && [[ -n $LOCAL_HISTFILE ]]; then
        local histfile_local=${HOME}/.bash_history.d/${DIRENV_FILE%\/*}
        mkdir -p $(dirname $histfile_local)
        touch $histfile_local
        chmod 600 $histfile_local
    else
        local histfile_local=${HOME}/.bash_history
    fi

    [[ "$HISTFILE" == "$histfile_local" ]] && return

    # switch history to new file
    echo "Writing Bash history to $histfile_local"

    history -w
    history -c

    export HISTFILE=$histfile_local

    history -r
}

PROMPT_COMMAND="_set_local_histfile;$PROMPT_COMMAND"
#+end_src

The function ~_set_local_histfile~ runs before/after each command you run. The first
thing it does is instantly appends the current history to the history file (~history
-a~). Then it checks to see if we have enabled local history and, if so, makes a new
history file in your home directory under ~.bash_history.d~. I wanted to keep all
history in my home directory rather than in the project directory just in case the
project is on an NFS mount or something and I can't or wouldn't want to write history
there. It's also important to set a strict access control on history files (in case you
type passwords or something). Then, if a local history file is in use, we write out the
current history, clear current history, switch file and read the new history file, as
laid out above.

Finally, I chose to make this an option rather than setting it whenever a ~.envrc~ file
is in use, so to use this set ~LOCAL_HISTFILE=1~ in ~.envrc~:

#+begin_src bash
echo 'export LOCAL_HISTFILE=1' >> .envrc
#+end_src

Or to make it a tiny bit nicer you can define a command in your ~.direnvrc~:

#+begin_src bash
use_localhist() {
    export LOCAL_HISTFILE=1
}
#+end_src

Then you can use simply ~use localhist~ in an ~.envrc~.

[fn:6] Direnv does not run the ~.envrc~ file in the current shell but in a subshell and
then inspects changes to the environment in the subshell.

** Conclusion

Learning to use history can really improve your proficiency on the command line and with
a few simple tweaks in your ~.bashrc~ it becomes even more useful and, sometimes, a
lifesaver.

Increasing the size of your history and preventing history loss is the kind of thing
you'll wish you enabled yesterday, so you might as well do it now. The local history one
is a bit more niche, but can be very useful for people like scientists doing a lot of ad
hoc data processing on the command line.

* DONE Using Nerd Icons in Org Agenda                         :emacs:orgmode:
CLOSED: [2023-11-14 Tue 23:56]
:PROPERTIES:
:EXPORT_FILE_NAME: org-agenda-nerd-icons
:END:

** Introduction                                                      :ignore:

Org mode supports icons in its agenda views.  The icons can be given as either file
paths to images (like SVGs), as image data or as a display property.  I use a [[https://www.nerdfonts.com/][Nerd Font]]
along with the [[https://github.com/rainstormstudio/nerd-icons.el][nerd-icons]] package in my Emacs config, so I thought I might as well
enable icons in my org agenda views.

[[file:/emacs/org-agenda-icons.png]]

The nice thing about using nerd fonts is this works perfectly in text mode too (assuming
you have a nerd font configured for your terminal emulator).

** The code

Since the nerd icons are accessible through a few different sets, I first wrote a
function to convert a "simple" alist icon specification into an alist org-mode expects:

#+begin_src elisp
(defun gk-nerd-agenda-icons (fun prefix alist)
  "Makes an org agenda alist"
  (mapcar (pcase-lambda (`(,category . ,icon))
            `(,category
              (,(funcall fun (concat prefix icon) :height 1.0))))
          alist))
#+end_src

I use this function like so to create my mapping from categories to icons:

#+begin_src elisp
(setq org-agenda-category-icon-alist
      (append
       (gk-nerd-agenda-icons #'nerd-icons-mdicon "nf-md-"
                             '(("Birthday" . "cake_variant")
                               ("Diary" . "book_clock")
                               ("Holiday" . "umbrella_beach")
                               ("Chore" . "broom")
                               ("Regular" . "autorenew")
                               ("Sprint" . "run_fast")
                               ("Database" . "database")
                               ("ELT" . "pipe")
                               ("Devops" . "gitlab")
                               ("Blog" . "fountain_pen_tip")
                               ("FOSS" . "code_braces")
                               ("Tool" . "tools")
                               ("Todo" . "list_status")))
       (gk-nerd-agenda-icons #'nerd-icons-sucicon "nf-custom-"
                             '(("Emacs" . "emacs")
                               ("Org" . "orgmode")))
       '(("" '(space . (:width (11)))))))
#+end_src

The final entry is a default match and puts a space of 11 pixels when the category
doesn't match any entry in the list. You'll have to play around with the number of
pixels here as it depends on your font.

You can adjust the ~:height 1.0~ part to make the icons bigger or smaller in a graphical
emacs. You'll have to experiment with this and it will depend on the font you use.

The final thing you probably need is a modification to ~org-agenda-prefix-format~.  The
reason this is necessary is because some icons take up too much space and make the lines
in the agenda overflow on the right. This will depend on your font also, but to fix
overflowing lines, make sure your ~org-agenda-prefix-format~ entries include
~%-2i~. This means org will include two characters for the icon in its calculation of
line width.

#+begin_src elisp
(setq org-agenda-prefix-format '((agenda . " %-2i %-12:c%?-12t% s")
                                 (todo .   " %-2i %-12:c")
                                 (tags .   " %-2i %-12:c")
                                 (search . " %-2i %-12:c")))
#+end_src

You can, of course, remove the category text (~%-12:c~) completely now, if you wish.

** Limitations

This is actually a bit of a hack as what org agenda is actually doing here is using our
options as a display property passed to ~propertize~.  It works because a display
property can be a string, which is just displayed in place of whatever is being
"propertized".

Unfortunately this means there are some limitations: you can't apply other display
properties, nor are recursive display properties supported (ie. using ~(propertize icon
...)~ /as/ the display property). So there can be some alignment issues and you can't
change the colours of the icons.

Perhaps it's possible to patch to org-mode to properly support propertized text as the
icon. The difficulty might be making it backwards compatible with current behaviour.

Before I do that I'll see if I actually enjoy using icons enough over the next few
weeks...

** Alternative approach

An equally hacky, but much easier, way is just setting the category in your org files to
the nerd icon:

#+begin_src org
,* Database                                                            :@work:
:PROPERTIES:
:CATEGORY: 󰆼
:END:
#+end_src

Then something like:

#+begin_src elisp
(setq org-agenda-prefix-format '((agenda . " %-2c%?-12t% s")
                                 (todo .   " %-2c")
                                 (tags .   " %-2c")
                                 (search . " %-2c")))
#+end_src

This means you can't practically use the categories for filters and stuff, though.

Happy hacking!

* TODO Git is your Safety Rope                          :git:vcs:development:
:PROPERTIES:
:EXPORT_FILE_NAME: git-safety-rope
:END:

** Introduction                                                      :ignore:

When I was learning rock climbing I distinctly remember my instructor telling me "you'll
never get good until you learn to trust the rope".

This principle seems to ring true in many areas of life.  You'll never really push
yourself if you think there's a high chance of a catastrophe.  That's why we have things
like insurance, backups and, well, safety ropes.

But wait, isn't git the thing I need protecting from?  Like any powerful tool, git can
do the wrong thing if wielded incorrectly.  But if you follow just a few simple rules,
it's literally impossible for git to break anything.

** Version control without git

A version control system allows you to store and access multiple version of the same
codebase.  It's worth imagining what this might look like without git, so let's invent
our own version control.

First let's make our project and create a README:

#+begin_src bash
mkdir my-project
echo "hi" > my-project/README
#+end_src

This is a pretty good start, so let's *commit* this version:

#+begin_src bash
cd ..
cp -pr my-project my-project-v1
#+end_src

An important rule in our system is that we must never touch any committed version again.
But we continue to work on the original copy.  This copy is known as the *working
directory*.

So we make another change:

#+begin_src bash
echo "more stuff" >> my-project/README
echo "new file stuff" >> my-project/new-file
#+end_src

Let's check what the difference is compared to v1:

#+begin_src bash
diff -Nur my-project-v1 my-project
#+end_src

#+begin_src diff
diff -Nur my-project-v1/new-file my-project/new-file
--- my-project-v1/new-file	1970-01-01 01:00:00.000000000 +0100
+++ my-project/new-file	2023-09-12 22:53:23.421997103 +0100
@@ -0,0 +1 @@
+new file stuff
diff -Nur my-project-v1/README my-project/README
--- my-project-v1/README	2023-09-12 22:52:44.806065953 +0100
+++ my-project/README	2023-09-12 22:53:13.246015242 +0100
@@ -1 +1,2 @@
 hi
+more stuff
#+end_src

Let's commit this new version:

#+begin_src bash
cp -pr my-project my-project-v1-1
#+end_src

Notice we called it ~v1-1~ instead of ~v2~.  This means it's the first version descended
from ~v1~.  To see why this is important, let's first check out ~v1~ again:

#+begin_src bash
rsync -a --delete my-project-v1/ my-project/
#+end_src

Now we make a completely different change:

#+begin_src bash
echo "something different" >> my-project/README
#+end_src

Remember we can always check the diff:

#+begin_src bash
diff -Nur my-project-v1 my-project
#+end_src

#+begin_src diff
diff -Nur my-project-v1/README my-project/README
--- my-project-v1/README	2023-09-12 22:52:44.806065953 +0100
+++ my-project/README	2023-09-12 23:14:10.060730295 +0100
@@ -1 +1,2 @@
 hi
+something different
#+end_src

And now we can commit this version, which is the second version descended from ~v1~:

#+begin_src bash
cp -pr my-project my-project-v1-2
#+end_src

We now have two branches that diverge at ~v1~.

OK, you probably get the idea.  This is basically how git works, The difference is git
makes it possible (and efficient) to have literally /millions/ of versions of the same
codebase on your filesystem.  But it's essentially doing the same thing behind the
scenes: making copies and storing the parent/child relationships between copies.

** You can't touch the blob store

In our version control system we had the rule that we would never touch any committed
version again.  Git has the very same rule.  Git stores all the committed versions in
its blob store and the blob store is an *immutable, append-only database*.

This is possibly the most fundamental thing to understand about git.  It will not ever
delete things from the blob store[fn:1]. So this is the key: to not lose anything you
need to get it into the blob store.  Your working directory is /not/ in the blob store.
To get stuff into the blob store, you need to commit it.

TODO:

- Commands that can corrupt worktree: ~git reset --hard~
- ~git worktree~ to make a new worktree
- push can affect other people so be careful and responsible

[fn:1] OK, "not ever" is a lie.  Git does actually delete unreachable items from its
blob store, but this is mainly stuff created by internal operations.  The process is
called garbage collection.  In practice this doesn't matter because you can't
practically get at those blobs anyway, but it does also prune the reflog, removing
anything older than 90 days, by default.  This is a bit less good but, again, in
practice 90 days is probably more than long enough.

* TODO Calendars                                               :calendar:gui:
:PROPERTIES:
:EXPORT_FILE_NAME: calendars
:END:

Why are we still using paper-like calendars?

Bit about Gutenberg press.

HN comments:

Thunderbird has the only calendar I know that has a "multiweek" display as opposed to
(well, in addition to) the utterly retarded month view that exists in every other GUI.

We've been doing electronic calendars for how long now? Why are we still using a
paradigm from paper based calendars? At the beginning of a month I can see three weeks
ahead, but at the end of the month I can see three weeks behind. It frustrates me no end
that this is still a thing. It reminds me of the early days of Google maps when they
were no better than paper maps, but now we can rotate the map, zoom in and out etc. But
calendars are still no better than paper calendars. Apart from the one in Thunderbird.

---

It did have zoom, but they were fixed levels so no different to having multiple paper
maps at different scales. Yes, of course there is the advantage that it's "not paper",
but that was the only advantage really. This is not unexpected at all as new technology
very often mimics existing technology in its first iteration. If you look at the first
outputs of the Gutenberg press you can see they were trying to mimic handwritten books
of the time. But usually the new technology very quickly surpasses the old after the
first iteration, as electronic maps have now done.

* DONE Custom Static Vector Maps on your Hugo Static Site    :hugo:blog:maps:
CLOSED: [2023-10-27 Fri 00:11]
:PROPERTIES:
:EXPORT_FILE_NAME: hugo-static-site-maps
:EXPORT_HUGO_LASTMOD: [2023-10-30 Mon 22:52]
:END:

** Introduction                                                     :ignore:

This blog is a static site built with [[https://gohugo.io/][Hugo]].  Being static means it can be served from a
basic, standard (you might say /stupid/) web server with no server-side scripting at
all.  In fact, this blog is currently hosted on Github Pages, but it could be anywhere.

Up until now, if you wanted to include an interactive map on a static site you were
limited to using an external service like Google Maps or Mapbox and embedding their JS
into your page.  This would then call to their non-static backend service to produce
some kind of tiles for your frontend.

But we can now put truly static maps into a static site.  Behold!

#+hugo: {{<map tiles-url="/bangor.pmtiles" bounds="-4.178753,53.215670,-4.137597,53.231163" max-bounds="-4.199352,53.210916,-4.116955,53.235941">}}

This isn't coming from a backend tile server.  This is all completely static, it's all
hosted on GitHub Pages and the above map uses less than 2 MiB of storage.  What's more
it's really quite easy to get started.  Let's see how it's done.

Although I'm using Hugo as a concrete example below, all of this should be easily
translatable to any static site.

** Generating a PMTiles basemap

The magic here starts with [[https://protomaps.com/][Protomaps]] and the PMTiles format.  PMTiles is an archive
format for tile data which is designed to be accessed with HTTP range requests.  As long
as the backend server supports HTTP range requests[fn:2] then the client can figure out
which requests to make to get the tiles it needs.

This means our map data can be hosted anywhere, just like our static site.

You can create a PMTiles archive from raw map data (such as OpenStreetMap), but the
easiest way is to extract data from an existing archive.  The Protomaps project produces
[[https://maps.protomaps.com/builds/][daily builds]] of the entire world from OSM data.  These files are over 100 GiB but you can
extract a much smaller file without downloading the whole thing.

First download the latest release of go-pmtiles from [[https://github.com/protomaps/go-pmtiles/releases][GitHub]] for your platform and
extract it somewhere (preferably somewhere on your ~PATH~ like perhaps ~~/.local/bin~).

Next you need to calculate a bounding box for your extract.  I used [[http://bboxfinder.com][bboxfinder.com]].
Draw a rectangle then copy the *box* at the bottom.  It should look something like
~-16.273499,27.508271,-14.889221,28.386568~.

Make sure you keep a note of this bounding box for later!

Now, using ~pmtiles~ that you just installed, you can create your extract like so:

#+begin_src bash
pmtiles extract \
        https://build.protomaps.com/20231001.pmtiles \
        mymap.pmtiles \
        --bbox=-16.273499,27.508271,-14.889221,28.386568
#+end_src

You can test your basemap by visiting [[https://protomaps.github.io/PMTiles/]] and selecting
your newly created pmtiles file.

Finally, put your PMTiles file into your Hugo static directory, for example
~static/mymap.pmtiles~.

[fn:2] Most do, but not all. Notably I found the dev server used by the [[https://parceljs.org/][Parcel]] bundler
does not, which led to much head scratching.

** MapLibre GL

Now you have a PMTiles extract you're happy with we need to render it somehow.  For this
we can use [[https://github.com/maplibre/maplibre-gl-js][maplibre-gl]].

If you haven't already, in your Hugo project directory initialise an npm project:

#+begin_src bash
npm init
#+end_src

Now install the required packages:

#+begin_src bash
npm install pmtiles
npm install maplibre-gl
npm install protomaps-themes-base
#+end_src

Now add the following as a JavaScript asset at ~assets/js/map.js~:

#+begin_src js
import * as pmtiles from "pmtiles";
import * as maplibregl from "maplibre-gl";
import layers from 'protomaps-themes-base';

let protocol = new pmtiles.Protocol();
maplibregl.addProtocol("pmtiles",protocol.tile);

function makeMap({tilesUrl, bounds, maxBounds, container = "map"}) {
    var map = new maplibregl.Map({
        container: container,
        style: {
            version: 8,
            glyphs: 'https://cdn.protomaps.com/fonts/pbf/{fontstack}/{range}.pbf',
            sources: {
                "protomaps": {
                    type: "vector",
                    url: `pmtiles://${tilesUrl}`,
                    attribution: '<a href="https://protomaps.com">Protomaps</a> © <a href="https://openstreetmap.org">OpenStreetMap</a>'
                }
            },
            layers: layers("protomaps","light")
        },
        bounds: bounds,
        maxBounds: maxBounds,
    });
    return map;
}

document.addEventListener('DOMContentLoaded', function(){
    document.querySelectorAll("div.map").forEach((e) => {
        makeMap({
            tilesUrl: e.dataset.tilesUrl,
            bounds: e.dataset.bounds.split(",").map(parseFloat),
            maxBounds: e.dataset.maxBounds.split(",").map(parseFloat),
            container: e,
        });
    });
});
#+end_src

What this does is finds every ~div~ on your page with the class ~map~ and creates a
maplibre-gl map there.  It expects the ~div.map~ elements to have data attributes which
it uses to set up the map.  Each ~div~ should look like this:

#+begin_src html
<div class="map"
     data-tiles-url="mymap.pmtiles"
     data-bounds="-16.273499,27.508271,-14.889221,28.386568"
     data-max-bounds="-16.273499,27.508271,-14.889221,28.386568"
</div>
#+end_src

The bounds are what you saved earlier from running ~pmtiles~.  You should definitely set
~max-bounds~ the same as your original bbox, but you can set ~bounds~ smaller, like I
have (bounds is the default zoom, maxBounds is the maximum span of the map).

Now let's put it all together with Hugo.

** Building with Hugo

This section is quite dependent on your site and theme set up, so I can't give
specifics, but I hope you already have an idea of where to put CSS or JavaScript etc.
Some themes include provision for an ~extra-head.html~ or similar that you can put in
~layouts/partials~.[fn:3]

*** JavaScript bundle

Most of the work will be done by the JavaScript above, but we first need to bundle and
include it in our pages.  This is done using Hugo Pipes.[fn:4]  Put the following in the
~<head>~ section of your site, near other scripts:

#+begin_src html
{{ $jsBundle := resources.Get "js/map.js" | js.Build "js/mapbundle.js" | minify | fingerprint }}
<script defer src="{{ $jsBundle.Permalink }}" integrity="{{ $jsBundle.Data.Integrity }}"></script>
#+end_src

*** CSS

You'll need a couple of bits of CSS, first we need to style the ~div.map~ elements with
some sensible default at least, so add the following to a style sheet:

#+begin_src css
div.map {
    width: 100%;
    height: 500px;
    margin-bottom: 1rem;
}
#+end_src

You also need maplibgre-gl's style.  First mount the stylesheet from ~node_modules~ in
Hugo's ~assets~ by adding to your Hugo config:

#+begin_src yaml
module:
  mounts:
    - source: "assets"
      target: "assets"
    - source: "node_modules/maplibre-gl/dist/maplibre-gl.css"
      target: "assets/css/maplibre-gl.css"
#+end_src

Do not forget the default mount for ~assets~.  Now in your ~<head>~ section add the
stylesheet:

#+begin_src html
{{ $style := resources.Get "css/maplibre-gl.css" | fingerprint }}
<link rel="stylesheet" href="{{ $style.Permalink }}">
#+end_src

*** Hugo shortcode

To insert the ~div.map~ element into your markdown posts you'll need a shortcode.  Put
the following in ~layouts/shortcodes/map.html~:

#+begin_src html
<div class="map"
     data-tiles-url="{{ .Get "tiles-url" }}"
     data-bounds="{{ .Get "bounds" }}"
     data-max-bounds="{{ .Get "max-bounds" }}">
</div>
#+end_src

Now you can simply use the shortcode anywhere in your site like so:

#+begin_src markdown
{{</*map tiles-url="/gran-canaria2.pmtiles" bounds="-15.923996,27.713926,-15.308075,28.205793" max-bounds="-16.273499,27.508271,-14.889221,28.386568"*/>}}
#+end_src

[fn:3] Overriding a theme is quite easy with Hugo, see:
[[https://bwaycer.github.io/hugo_tutorial.hugo/themes/customizing/]]

[fn:4] If you are unfamiliar with Hugo Pipes you can read all about it [[https://www.regisphilibert.com/blog/2018/07/hugo-pipes-and-asset-processing-pipeline/][here]].

** Conclusion

I can't believe how easy this has been for me to set up.  Here's to [[https://protomaps.com/][Protomaps]], [[https://maplibre.org/][MapLibre
GL]] and, of course, [[https://www.openstreetmap.org/][OpenStreetMap]]!

I had previously tried setting up my own custom maps and found it quite difficult to
get started, not to mention requiring me to run a special tileserver somewhere or use a
third party service.  I'm by no means a map expert (although I am an OpenStreetMap
contributor of many years, if that means anything), so I find this post a testament to
how far the work of the free/open mapping community has come.

Of course, this approach isn't suitable for everything and comes with drawbacks.  In
particular, your map will never receive updates unless you update the pmtiles file.
This could be particularly bad if your area doesn't have good OpenStreetMap coverage.

But, for me, this is static by design.  I /want/ these pages to be static, including the
map.  If I include a route showing where I walked, it doesn't make sense for it to
appear on some map of the future.  It /should/ be a map of the past.

Also, let's not forget that maps don't have to contain "real" data.  It could contain a
planned development or even just a fantasy world.  There are many possibilities.  Next
on my list to play is to try to get hillshading/relief into my maps.

To finish, just for fun, here's another map showing a recent multi-day walk across Gran
Canaria[fn:5]:

#+hugo: {{<map tiles-url="/gran-canaria2.pmtiles" relief-url="/gran-canaria-relief.pmtiles" tracks="/gc1.gpx,/gc2.gpx,/gc3.gpx,/gc4.gpx" bounds="-15.923996,27.713926,-15.308075,28.205793" max-bounds="-16.273499,27.508271,-14.889221,28.386568">}}

[fn:5] I've used [[https://github.com/jimmyrocks/maplibre-gl-vector-text-protocol][maplibre-gl-vector-text-protocol]] to add statically hosted GPX files to
the map.  See the [[https://github.com/georgek/blog][source]] of my blog to see how.

** Appendix

*** org-mode and ox-hugo

I don't write my blog in Markdown directly, but in org-mode first and use ox-hugo to
export it.  There are a [[https://ox-hugo.scripter.co/doc/shortcodes/][few]] ways to add shortcodes, but the neatest I've found for the
map shortcodes is simply:

#+begin_src org
,#+hugo: {{<map tiles-url="/bangor.pmtiles" bounds="-4.178753,53.215670,-4.137597,53.231163" max-bounds="-4.199352,53.210916,-4.116955,53.235941">}}
#+end_src

* DONE Why is Emacs Hanging?                                :emacs:debugging:
CLOSED: [2023-09-21 Thu 14:10]
:PROPERTIES:
:EXPORT_FILE_NAME: emacs-hangs-debug
:END:

Even after using Emacs for 15 years there's still so much I can learn. I probably should
have already known this, but there's a first time for everything.

It's rare that Emacs hangs. Exceedingly rare. Which is probably why I didn't know how to
deal with it. Today Emacs started hanging when trying to open files over a remote TRAMP
session (SSH).

The most important key of all that everyone who uses Emacs knows is ~C-g~. This is the
universal "quit" key and it has the power to interrupt any long running processes. What
I didn't know about is ~M-x toggle-debug-on-quit~. I've used ~toggle-debug-on-error~
extensively when programming Elisp (I even have it bound to a key in Elisp
buffers). ~toggle-debug-on-quit~ is similar except the debugger is invoked when you
~C-g~.

While this is enabled, I was able to reproduce the hang, then press ~C-g~. I could see
that what was happening is ~ess-r-package-auto-activate~ was being called via
~after-change-major-mode-hook~, this was in turn calling on TRAMP again to try to find
an R package or something. I don't regularly use ESS mode, so I simply disabled this
behaviour with ~(setq ess-r-package-auto-activate nil)~.

~toggle-debug-on-quit~ should be toggled off again aftewards, as quitting isn't actually
an error most of the time. Doom modeline handily displays an icon when it's enabled,
confirming that I'm the last person to know about this.

Something else interesting to consider here is packages can still affect Emacs
performance even if you aren't using them. I haven't used R or ESS mode for years, but
I've left them in my config because, why not? But these "dormant" packages can still be
impacting performance and it might be worth auditing hooks like
~after-change-major-mode-hook~ to check for packages you don't really need any more.

* DONE Replacing Strings in an Entire Project                  :emacs:regexp:
CLOSED: [2023-08-22 Tue 14:22]
:PROPERTIES:
:EXPORT_FILE_NAME: emacs-regexp-replace
:END:

This is a little trick I just applied and thought was cool enough to write down.

Let's say you want to replace a name that is used throughout a project.  Due to various
conventions/restrictions in use the name might appear in several forms like:
~MY_COOL_NAME~, ~my-cool-name~, ~my_cool_name~ etc.

In Emacs you can invoke regexp replace across an entire project by invoking
~project-query-replace-regexp~, by default bound to ~C-x p r~.  This will first prompt
for the regexp to search for, then what to replace it with.

For the search regexp we can put: ~my\([_-]\)cool\1name~.

This allows either underscore or hyphen as a separator.  Notice we use ~\1~ as the
second separator.  This is a "backreference" and simply refers to whatever was captured
in the first group, in this case ~\([_-]\)~.

We can then us the same backreference in the replacement, so we can put: ~new\1name~.

After pressing enter again emacs will then cycle through every replacement in every file
in the project allowing you to either apply it, with ~y~ or skip it, with ~n~.  If you
wish to make the changes across an entire file unconditionally, press ~!~.  If you wish
to skip an entire file, press ~N~.  You can also press ~?~ to see the other options.

Notice Emacs does what you (probably) want when it comes to case.  We didn't type the
search in upper case, but it will match ~MY_COOL_NAME~ and replace it with ~NEW_NAME~.
Similarly, if there were a ~My-Cool-Name~, it would replace it with ~New-Name~
automatically.

* DONE Install Calibre without Root                     :calibre:ebook:linux:
CLOSED: [2023-08-13 Sun 13:23]
:PROPERTIES:
:EXPORT_FILE_NAME: calibre-rootless-install
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :summary How to install Calibre on Linux without root and/or sudo
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :description The best way to install Calibre on Linux
:END:

** Introduction                                                      :ignore:

On Linux, software should generally be installed with your system package manager (apt,
yum, portage etc.)  However, Calibre is a bit "special" in this respect.  While
well-loved, it's known to be a bit difficult to package (to say the least) and most
distro packages you'll find are out of date.  The [[https://calibre-ebook.com/download_linux][official website]] recommends against
using any distro packages and instead installing it directly from the site.

Unfortunately, the official instructions are problematic for a number of reasons.  For a
start, copying and pasting commands from the browser is considered dangerous.  But
that's easy to fix, in bash do ~Ctrl-X Ctrl-E~ and your preferred text editor will be
opened for you to type your command.  This means you can inspect what is pasted before
is run (save the file then exit the editor to run the command).  Very important.  Always
do this when copy/pasting from the web.

But that's not all, it also has you run the installer as root.  The installer does tuck
everything nicely away inside ~/opt/calibre~, but it's just not a good idea for many
reasons.

** User-level installation

Instead you can install it in your home directory under ~~/opt~ like this:

#+begin_src bash
wget -nv -O- https://download.calibre-ebook.com/linux-installer.sh \
    | sh /dev/stdin install_dir=~/opt isolated=True
#+end_src

Or, even better, as a completely different user so any error in the script can't trample
anything in your home directory:

#+begin_src bash
sudo useradd calibre            # add new user the first time

wget -nv -O- https://download.calibre-ebook.com/linux-installer.sh \
    | sudo -u calibre sh -s install_dir=~calibre/opt isolated=True
#+end_src

Once finished it will tell you to run ~/home/<user>/opt/calibre/calibre~ to start.  If
you have ~~/bin~ (or perhaps ~~/.local/bin~) on your ~PATH~ you can add a nicer link
with the following:

#+begin_src bash
ln -s /home/<user>/opt/calibre/calibre ~/bin
#+end_src

Then you should be able to run simply ~calibre~.

** Desktop environment integration

If you need a menu item in a desktop environment then you might first need to add the
link to ~/usr/bin~ (this also makes it available for all users):

#+begin_src bash
sudo ln -s /home/calibre/opt/calibre/calibre /usr/bin/calibre
#+end_src

Then you need to make a desktop file called
~/usr/share/applications/calibre-gui.desktop~ with the following:

#+begin_src bash
[Desktop Entry]
Version=1.0
Type=Application
Name=calibre
GenericName=E-book library management
Comment=E-book library management: Convert, view, share, catalogue all your e-books
TryExec=calibre
Exec=calibre --detach %U
Icon=calibre-gui
Categories=Office;
X-GNOME-UsesNotifications=true
MimeType=image/vnd.djvu;application/x-cb7;application/oebps-package+xml;application/epub+zip;application/x-mobi8-ebook;text/plain;application/x-cbc;application/xhtml+xml;application/x-cbz;application/ereader;application/pdf;text/fb2+xml;application/x-mobipocket-subscription;application/x-cbr;application/x-sony-bbeb;text/x-markdown;text/html;application/vnd.oasis.opendocument.text;application/x-mobipocket-ebook;application/vnd.ms-word.document.macroenabled.12;application/vnd.openxmlformats-officedocument.wordprocessingml.document;text/rtf;x-scheme-handler/calibre;
#+end_src

You only need to make these links and desktop entry once.  Next time you update Calibre
they will point to the new version.

* DONE Writing a Blog with Org-mode             :emacs:orgmode:hugo:blog:gui:
CLOSED: [2023-07-15 Sat 13:43]
:PROPERTIES:
:EXPORT_FILE_NAME: hugo-org-mode
:EXPORT_HUGO_LASTMOD: <2023-10-08 Sun 20:52>
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :summary I've set up my blog such that I can write it using org-mode and host it and edit it anywhere. I'm using Hugo as a static site generator and GitHub as a host.
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :description How I set up this blog using emacs, org-mode and Hugo
:END:

** Introduction                                                      :ignore:

I've always thought I should write a blog, but I just never got around to setting it
up.  I know there are services you can simply sign up to and start writing, but that
isn't for me.  I have two requirements for this thing:

1. I can write using tools of my choice,
2. I can host it anywhere.

My tool of choice for writing anything is emacs and, for natural language in particular,
[[https://orgmode.org/][org-mode]].  This is a bit like markdown, but better.  For version control and deployment
I use git.

I also want to be able to host it anywhere because I don't want to be tied to a host
and, ideally, I don't want to pay for it either.  Back in the day it was common to use a
dynamic site for a blog.  Your content would live in a database and was served up using
some backend process like WordPress.  But that's too expensive and places too many
requirements on the host.

With that in mind, I've decided to use a static site generator.  This is ideal as it
means I don't have to write raw HTML myself (although you can) but the output can be
hosted anywhere.  I've decided to use [[https://gohugo.io/][Hugo]] simply because it looks good, seems fast,
well maintained, supports the workflow I want and, most importantly, supports org-mode.

** Using org-mode with Hugo

First of all, you set up your Hugo project by following the [[https://gohugo.io/getting-started/quick-start/][quickstart guide]].

The next thing I did was install the [[https://github.com/adityatelange/hugo-PaperMod/wiki/Installation][PaperMod theme]], as it seems like a decent default
for a blog.

Now, to start a new page using org-mode, you first need to install an [[https://gohugo.io/content-management/archetypes/][archetype]].  These
are essentially templates that Hugo uses to start new content.  By default it comes with
a markdown archetype in ~archetypes/default.md~.  You should add the following code in
~archetypes/default.org~:

#+NAME: archetypes/default.org
#+BEGIN_SRC org
,#+TITLE: {{ replace .Name "-" " " | title }}
,#+DATE: {{ .Date }}
,#+DRAFT: true
,#+DESCRIPTION:
,#+CATEGORIES[]:
,#+TAGS[]:
,#+KEYWORDS[]:
,#+SLUG:
,#+SUMMARY:

#+END_SRC

Now you can start a new org-mode post by running: ~hugo new posts/my-org-post.org~.
You'll find your org-mode file ready to edit in ~content/posts/my-org-post.org~.  The
metadata is pretty self-explanatory, but you can just play around with it.

** Deploying with Github Actions

First of all, *before* you build or commit anything, add a ~.gitignore~ file:

#+BEGIN_SRC
/.hugo_build.lock
/public/*
!/public/.nojekyll
#+END_SRC

This will ensure you don't accidentally commit your locally built version of the site.

You should also add the ~.nojekyll~ file to stop GitHub trying to run Jekyll (another
static site generator) on your stuff.  I'm not sure if this is still necessary but it
can't harm:

#+BEGIN_SRC bash
mkdir -p public
touch public/.nojekyll
#+END_SRC

Now commit the ~.gitignore~ and ~.nojekyll~ files.

To publish your site you simply run ~hugo~.  This builds the site, including all
articles that are *not* marked as draft, and puts it all into the ~/public/~ directory.
Now, you could simply copy the contents of that directory to a web server of your
choice.  That's how we did it back in the day.  This is how it meets my "can host
anywhere" requirement.

But I'm lazy and I want it to be easier.  I just want the site to build and deploy when
I push my changes to git.  This is actually remarkably simple to achieve with modern CI
tooling such as GitHub Actions.  Although, note: I won't be tied to GitHub or GitHub
Actions in any meaningful way, it's essentially a glorified copy at the end of the day
and I can always build my site on my own computer and copy the output the
"old-fashioned" way.

To build using GitHub simply add the following to ~/.github/workflows/hugo.yml~:

#+BEGIN_SRC yaml
name: hugo

on:
  push:
    branches: [master]

permissions:
  contents: write

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          submodules: true

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: '0.115.2'
          extended: true

      - name: Build
        run: hugo --minify

      - name: Deploy
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          branch: gh-pages
          folder: public
#+END_SRC

This pipeline is triggered by pushes to the ~master~ branch.  It checks out the code,
sets up Hugo with the same version that I used locally, builds using ~--minify~ (I don't
like minified pages generally, but the source is available freely so might as well save
bandwidth) and deploys it to the ~gh-pages~ branch.  Note that the source will live on
the ~master~ branch (or any other branch), the built version will end up on the
~gh-pages~ branch, which will then be deployed to Github Pages itself.

** Conclusion

This should be everything needed to get started writing a blog (or any static site) with
Hugo and hosting it on Github.  If you are reading this then I guess it worked!

Links to the tools in use:

- org-mode: https://orgmode.org/
- Hugo: https://gohugo.io/
- GitHub Pages: https://pages.github.com/
- actions-hugo: https://github.com/peaceiris/actions-hugo
- github-pages-deploy-action: https://github.com/JamesIves/github-pages-deploy-action

** Addendum

Now that I've written a few posts I've found the built-in org support of Hugo pretty
limiting.  It doesn't have first-class support like Markdown does.  Thankfully there is
the [[https://ox-hugo.scripter.co/][ox-hugo]] package which can export org-mode files to Markdown, before being read by
Hugo.

The layout for the project is a bit different as it leverages org-mode to handle tags
and categories in a nicer way, but it's mostly the same (I didn't really have to convert
my existing posts, but I did anyway).  The main difference is in how the project is
built.  The GitHub Actions pipeline contains one new entry to set up Emacs:

#+begin_src yaml
name: deploy

on: push

permissions:
  contents: write

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          submodules: true

      - name: Setup Emacs
        uses: purcell/setup-emacs@master
        with:
          version: 29.1

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: '0.118.2'
          extended: true

      - name: Build
        run: make

      - name: Deploy
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          branch: gh-pages
          folder: public
        if: github.ref == 'refs/heads/master'
#+end_src

The build step is now container within a Makefile and looks like this:

#+begin_src makefile
build:
	cd content-org && emacs --batch -Q --load ../publish.el --funcall gpk-publish-all
	hugo --minify
#+end_src

This runs Emacs in batch mode.  The file ~publish.el~ contains settings and functions
necessary for running ~ox-hugo~:

#+begin_src emacs-lisp
;;; publish.el --- publish org-mode blog                     -*- lexical-binding: t; -*-
;;; Commentary:
;;; original influence: https://github.com/NethumL/nethuml.github.io/

;;; Code:
(defconst gpk-content-files
  '("life.org"
    "networking.org"
    "programming.org"
    "software.org"
    "technology.org"
    "thoughts.org"))

;; Install packages
(require 'package)
(package-initialize)
(unless package-archive-contents
  (add-to-list 'package-archives '("nongnu" . "https://elpa.nongnu.org/nongnu/") t)
  (add-to-list 'package-archives '("melpa" . "https://melpa.org/packages/") t)
  (package-refresh-contents))
(dolist (pkg '(org-contrib ox-hugo))
  (package-install pkg))

(require 'url-methods)
(url-scheme-register-proxy "http")
(url-scheme-register-proxy "https")

(require 'org)
(require 'ox-extra)
(require 'ox-hugo)
(ox-extras-activate '(ignore-headlines))

(defun gpk-publish-all ()
  "Publish all content files"
  (message "Publishing from emacs...")
  (dolist (file gpk-content-files)
    (find-file file)
    (org-hugo-export-wim-to-md t)
    (message (format "Exported from %s" file)))
  (message "Finished exporting to markdown"))

;;; publish.el ends here
#+end_src

As you can see from the comment, this was "influenced" (ie. taken) from another blogger
and can be found [[https://nethuml.github.io/posts/2022/06/blog-setup-with-hugo-org-mode/][here]].

# Local Variables:
# org-footnote-section: nil
# End:
