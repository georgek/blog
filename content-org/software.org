#+author: George Kettleborough
#+hugo_draft: t
#+hugo_base_dir: ../
#+hugo_categories: Software
#+html_container: section
#+html_container_nested: t

* TODO Git is a Version Control System                              :git:vcs:
:PROPERTIES:
:EXPORT_FILE_NAME: git-is-a-version-control-system
:END:

** Introduction                                                      :ignore:

The title of this post isn't supposed to be provocative. After all, it's simply the
textbook definition of what git is. So why bother stating it? Well, I've worked with a
fair few junior developers now and I'm starting to see a pattern. Many of these
developers have never programmed /without/ git and they see git simply as "the way to
get new code into a repository". A glorified copy, essentially---but an annoying one
that is prone to going wrong.

But git is so much more than a glorified copy. In this post I want to go back to basics
and show what a version control system is and what it can do for you. I hope this will
provide a different view of git that might help you in your git journey.

** Dumb version control

Back in the day, before everything was on the cloud, it was frighteningly common to see
the following turn up in an email attachment:

~important-document-v6-2024-02-16-(gpk).doc~

People who knew better would scoff at this, but what you're seeing here is version
control. It's just very manual, dumb version control. It was scoffed it because it's the
kind of thing that is prone to going wrong, but if implemented very carefully, it could
go right. Here's how it might work:

1. Type up the first version of a document, say ~important-document.doc~,
2. Make a copy of that, called ~important-document-v1.doc~,
3. Continue making further additions/edits to ~important-document.doc~,
4. Make another copy of that, called ~important-document-v2.doc~.

The important thing here is discipline. For this to go well, the ~v1~, ~v2~ documents
must never be edited again or you'll undermine the whole system. To make it easier to do
the right thing the dumb version control user might opt to keep the untouchable copies
in a hidden directory, like ~.vcs~, which might look like:

#+begin_src :linenos false
.
├── important-document.doc
└── .vcs
    ├── important-document-v1.doc
    └── important-document-v2.doc
#+end_src

What about those other parts in the first example, like the ~(gpk)~? These are to enable
collaboration. The way this worked is you would send ~v6~ to me, then continue working
and produce a ~v7~. Later, I would send you back some corrections. You now have two
branches that need to be reconciled. And that's exactly what people would do, they would
go through the corrected ~v6-(gpk)~ and apply all the changes to ~v7~. People just kept
this stuff in their head and, for the most part, it kind of worked.

** Git is dumb version control

The big secret is git is, in essence, nothing more than an implementation of the above
system, with one small difference.

The first thing to understand about git is *a commit is a copy of your entire working
directory*. This also means a commit and a version are the same thing. Just like the
dumb system, making a commit is nothing more than copying the current *working
directory* into a separate storage place. With git, the storage place is actually a
~.git~ directory.

The second, and arguably most important, thing to understand is *commits are
immutable*. Remember in the dumb system we said we must not ever touch the ~v1~, ~v2~
etc. copies? Git enforces this. There is no command in git that can modify, overwrite or
delete any commit that has been made.[fn:8]

The small difference between the dumb system and git is what version numbers look
like. In the dumb system we used a linear sequence of numbers. But this falls apart as
soon as we have a second person working on a project. Essentially, my ~v2~ and your ~v2~
are different versions and if we ever hope to merge these together the system needs to
be able to store them and refer to them at the same time.

There are many solutions to this problem, but git's solution is simple: it uses the hash
of the entire commit as the version number. These are virtually guaranteed to be
universally unique. But, since hashes are not sequential, it also stores a link to the
previous version with every version to establish the lineage.

[fn:8] Of course, this is only true if you operate within the confines of git. Git can't
help you if you ~rm -rf~ your entire repo or something. There is also garbage
collection, but this can be safely ignored in normal usage and even disabled if you
really wish.

** Doing dumb things with git

So how do we actually use git? Let's compare and contrast the dumb version control
system with git. Note the dumb VCS commands are supposed to be illustrative and almost
certainly don't work in all cases (like with hidden files/dirs). Also note, when there
are multiple commands they are to be taken together as atomic operations; I'm not saying
the individual commands are analogous to each other.

*** Making a commit

To make a new commit in the dumb system we copy the working copy into the ~.vcs~
directory:

#+begin_src sh
mkdir .vcs/v6
cp -r * .vcs/v6
#+end_src

Note we have to somehow know that ~v6~ is the next version number.

In git we do:

#+begin_src sh
git add -A
git commit -m "New version"
#+end_src

We didn't have to know the previous version number, nor the new version number. Git
instead tells us the hash of the new version after it's done.

*** Checkout an old version

In the dumb system we must first wipe our working copy then copy the version we want:

#+begin_src sh
rm -r *
cp -r .vcs/v1/* .
#+end_src

Note the symmetry between commit and checkout.

With git we need to specify a version somehow. We could use a hash, or a relative lookup
like ~HEAD^~, which means the previous commit to the one currently checked out (recall
git stores a link to the previous commit with every commit):

#+begin_src sh
git checkout HEAD^
#+end_src

Git warns us about being in a detached head state because anything you do in this state
is kind of difficult to keep track of unless you're good at remembering commit hashes.

It turns out checkout is actually a pretty rare thing to do in git, but it's included
for completeness.

*** Using meaningful version labels

In the dumb system the version labels are up to us. The ~v1~ labels are already
meaningful, but we could use even more meaningful labels if we wish:

#+begin_src sh
mkdir .vcs/v6-test2
cp -r * .vcs/v6-test2
#+end_src

In git, we can't change the hashes, but we can add as many /additional/ labels to a
commit as we like. There are two types of labels in git: branches and tags.

To create a new branch ~new-branch~ that labels a commit ~124b7c6~:

#+begin_src sh
git branch new-branch 124b7c6
#+end_src

To create a tag ~new-tag~ that labels the same commit:

#+begin_src sh
git tag -am "New tag" new-tag 124b7c6
#+end_src

Note that in both cases we have only added /labels/ to existing commits. Nothing else
has changed.

We can use our meaningful names instead of hashes, for example to create another tag
for the very same commit:

#+begin_src sh
git tag -am "Another tag" another-tag new-branch
#+end_src

The difference between branches and tags are branches are mutable while tags are
immutable. If you make a commit git *updates* your current branch (if there is one) to
point to the new commit. Tags, on the other hand, will forever point to the same commit.

*** What is the current version/branch?

In the dumb system you just store the current version in your head. Since we were using
sequential numbers you could know by inspecting the ~.vcs~ directory and seeing the
largest number is ~v6~. This is how you would know the next version is to be ~v7~.

Git stores the current version/branch in /its/ head. Quite literally, in a file called
~HEAD~. You can check this in any git repository by running ~cat .git/HEAD~. You would
probably see something like ~ref: refs/heads/master~.

This is how git "knows" what the previous version is when you make a commit. It's also
how it knows which branch to update when you make a commit.

You can use ~HEAD~ as a label in its own right as we saw above when we checked out
~HEAD^~ (the ~^~ is a relative lookup and means the parent of ~HEAD~ in this case).

A detached head state happens when you checkout a commit directly using its hash. If you
were to look at ~.git/HEAD~ in this state you would see an entire commit hash instead of
a ref. If you make commits in this state there is no branch to update so these commits
can only be found using their hash. Git warns you before and after leaving a detached
head state. If in doubt, create a branch like it tells you to do!

*** Syncing with a remote

With the dumb system, syncing to a remote can be done using any sync tool, like rsync:

#+begin_src sh
rsync .vcs my-server:my-project
#+end_src

This copies just the ~.vcs~ directory so everything we have so far committed.

Git is much more clever in this regard as it tries to minimise the amount of data it
sends and manages your remotes itself, but you can do something similar like this:

#+begin_src sh
git remote add my-remote my-server
git push my-remote --follow-tags '*:*'
#+end_src

This pushes all commits as well as all branches and all tags.

Note that in neither case is your working directory transferred. Only things you have
already committed.

*** Differences between versions

In the dumb system, we can use the standard ~diff~ tool to see the differences between
two versions:

#+begin_src sh
diff -ur .vcs/v2 .vcs/v3
#+end_src

Git has a much more powerful and specialised diff tool built in and there are many
different ways to invoke it, but to compare two versions, say ~a1bf365~ and ~main~ it
looks almost the same:

#+begin_src sh
git diff a1bf365 main
#+end_src

** Beyond dumb version control

So why use git at all then? So far we've seen it can all be done using simple tools and
some discipline. Let's look at what git can do beyond the dumb system.

*** Tracking branches

When you add a remote, git automatically downloads everything---all commits and all
branches and tags---from that remote and keeps a copy of it all locally. The branches
end up as locally immutable branches in your local clone called /remote-tracking
branches/.

They are locally immutable in the sense that they can only be updated to reflect the
state of the remote when syncing with the remote. You can't update these branches any
other way. The branch names will be prefixed with the remote name, like
~my-remote/my-branch~ and can be safely updated at any time by running ~git fetch~.

Git allows you to set any other branch as the /upstream/ of a branch. The meaning of
upstream is usually "the branch I eventually want my changes merged into". You could set
~my-remote/my-branch~ as the upstream of your current branch like so:

#+begin_src sh
git branch -u my-remote/my-branch
#+end_src

When you check the status of your local branch git can now tell you useful information
like "Your branch is ahead of 'my-remote/my-branch' by 1 commit." If you periodically
sync with the remote using ~git fetch~ you can see how far behind the upstream branch
you are getting.

*** Merging

Both of our systems allow branching, but branching isn't very useful without merging. In
the dumb version control system merging is a laborious process of combing through both
versions and creating a combined version.

With git you can create such a "combined" version with one command:

#+begin_src sh
git merge another-branch
#+end_src

This automatically calculates all the changes on ~my-branch~ that don't exist on your
current branch and applies them, creating a new merge commit. Sometimes there are
conflicts, like if both you and them touched the same line in different ways. Git can't
resolve these conflicts automatically so presents them to you to resolve before
completing the merge.

*** Rebasing

Often when working on a feature for a while you will find your local branch and your
upstream branch will diverge due to other changes happening upstream. If you set your
upstream as above, git will say something like "Your branch and 'my-remote/my-branch'
have diverged, and have 8 and 1 different commits each, respectively."

This means you've got 8 commits locally that haven't been merged and the upstream has 1
commit that you haven't yet seen. Over time the upstream will get more commits and the
longer this happens, the higher the chances of difficult merge conflicts happening later
(remember, the only point of a branch is to be able to merge it).

You can keep on top of this by "rebasing" your local branch on to the upstream like
this:

#+begin_src sh
git rebase
#+end_src

What git does is takes those 8 commits on your branch and, one by one, re-applies the
changes to the top of the upstream. This can cause conflicts but the hope is if you
rebase frequently the conflicts are smaller and the changes you are applying are still
fresh in your head. By keeping on top of this you'll never diverge too far from upstream
and be stuck with a difficult merge before you can finish your work.

Rebasing also allows you to edit the commits as they are being re-applied. This is very
powerful and is one way you can "clean up" a local working branch ready for it to be
reviewed and merged.

*** Resetting

Reset is one of the scarier git commands and that is somewhat justified given that it
has the ~--hard~ option. This is one of the few commands that can actually overwrite
your work. But remember, *no command in git can change, delete or overwrite commits* so,
when in doubt, commit your work!

Resetting tells git to point your current branch at a different commit. Normally
branches are only updated when you make new commits, as mentioned above. But there a few
reasons why it's useful to point a branch at some other commit.

One reason to reset is to simply undo any changes in your working directory, this uses
the scary ~--hard~ option to intentionally overwrite your working directory.

Another is to re-commit some changes using a different set of commits. Perhaps you made
a chain of "work in progress" commits and want to rewrite it as one final commit. You
can ~--soft~ reset to the commit before the first WIP commit then commit your changes
again. This can also be achieved with a rebase but sometimes the reset is easier.

One more reason is if you have a branching model like git's own git repository which has
a ~next~ branch for "pre-release" features. This branch is reset to the top of ~master~
after each release. Complicated branching structures like this aren't recommended if you
don't need them, but git gives you the option.

Finally, resetting is how you make use of the reflog...

*** The reflog

What happens to the "old" commits following a rebase or a reset? I've already mentioned,
and it's worth mentioning again, that no command in git can delete commits. However,
unless you somehow remember their commit hashes, commits are no longer practically
reachable without some kind of reference (ie. a branch or tag).

That's where the reflog comes in. Since branches are mutable, git keeps a log of all
changes to a branch including commits, rebases and resets. If you want to "undo" a
rebase or a reset, the reflog is where you need to look. Following a rebase or reset,
the reflog might be the only way to find some commits.

You can view the reflog for you current branch by running ~git reflog~.

The reflog will be automatically pruned after 90 days by default. After that time, the
commits themselves will *actually be deleted*. This is to prevent git repos growing
indefinitely. So, yes, I have been lying when I said commits can never be deleted, but
there is a time delay of at least 90 days following any command before they will be. For
this reason you shouldn't be regularly using the reflog to find important commits;
always make sure important stuff is referenced by tags or branches.

The reflog is your safety rope and I thoroughly recommend exercising your safety rope
until you are confident in how git works. Do a stupid rebase and undo it using the
reflog:

#+begin_src sh
git rebase some-silly-place
git reset HEAD@{1}
#+end_src

The way to read the second command is "reset my current branch to where my current
branch was one operation ago".

The reflog can't save you if you're in a detached head state, though, because there's no
ref to record the changes against. This is why git warns you about it and gives you
every opportunity to record the hashes of any commits you make. Just heed the warnings
and be careful in a detached head state.

** Conclusion

Version control can be difficult. Some of that difficulty is naturally inherited by
git. Git adds to the difficulty with a somewhat cumbersome UI. But I do believe most of
the difficulties stem from misconceptions and not starting with a basic idea of what
version control is.

I'm amazed by how many people, even experienced developers and git users, think git
stores diffs and does something more clever than our dumb version control system to make
and checkout commits.[fn:9] This is a bad start when it comes to understanding git.

In my career I've always found myself being the "git guy". I don't know why this
is. This article is an attempt for me to teach git in a slightly different way, starting
at a lower level with no preconceptions of what version control is which is, I think,
how I learnt it. Whether this is a useful way to learn or not remains to be seen. I'd
love to hear feedback either way!

[fn:9] OK, it does do something a lot more clever than ~cp -r~ internally but, as a
user, you do *not* need to know or worry about that. The details are fascinating if you
are interested, though.

* DONE Emacs Undo Redo                                                :emacs:
CLOSED: [2023-12-14 Thu 22:18]
:PROPERTIES:
:EXPORT_FILE_NAME: emacs-undo
:END:

** Introduction                                                      :ignore:

At first glance, undo seems like a simple thing expected of most software these days and
hardly worth writing about. Indeed, when I say Emacs has a very powerful undo
system---probably more so than any other text editor---you may wonder what could make an
undo system powerful. So let's start by considering two big problems most undo systems
have:

1. If you undo something, make some changes, then change your mind, what you undid is
   now lost and unrecoverable,
2. If you make changes in two parts of the same file you cannot undo changes in the
   first part without undoing changes in the second part too.

Emacs comes with solutions to each of these out of the box. Read on to understand how it
works and how we can improve upon the defaults even more.

** Standard undo system

To deal with the first problem, it's quite simple: Emacs stores undo commands themselves
in the undo history. To understand how this works, imagine a situation where you've made
two changes to a buffer and are now in state ~c~. The history would look like this:

#+begin_example
   a---b---c
           ^
#+end_example

If you now undo twice, you will get back to state ~a~, as you would expect, and the
history will look like this:

#+begin_example
   a---b---c
   ^
#+end_example

So far, so good, but what happens if we now make a non-undoing change such as entering
some new text to get into state ~b'~. In most editors, states ~b~ and ~c~ would at this
point be lost, but in Emacs we get the following history:

#+begin_example
   a---b---c---b---a---b'
                       ^
#+end_example

What's happened is the moment a command breaks the chain of undos, the chain of undos
are themselves added to the undo history before any subsequent changes. This means you
can always get back to /any/ previous state, including ~b~ and ~c~.

This might sound quite hard to understand but, in fact, it's actually quite intuitive
and I used this standard undo system for many years.

** Undo-tree

Another way to understand the states above is as a tree:

#+begin_example
     a
    / \
   b   b'
   |   ^
   c
#+end_example

Now it's perhaps possible to see that Emacs undo is actually doing a kind of tree
traversal but, by default, you can't see the tree, you just have to imagine it.

But what if it's too difficult to imagine? That's where [[https://www.dr-qubit.org/undo-tree.html][undo-tree]] comes in. Undo-tree
replaces the standard undo system with an alternative system that gives the standard
undo/redo commands while still retaining full access to the tree when you need it. It
comes with a graphical tree browser so you can view the undo tree and move anywhere
within it.

I should have installed undo-tree years ago. As it happens, I've only started using it
recently, but now an even better alternative is available.

** Vundo

How I thought undo-tree worked was it used the standard Emacs undo system but merely
enabled easier navigation through undo states by displaying a tree. This isn't right, it
actually replaces the undo system completely, but this /is/ how [[https://github.com/casouri/vundo][vundo]] works. With vundo
you use the standard undo system as described above, but you can display it as a tree
and navigate through it when you need to.

But vundo would not be competitive with undo-tree if it weren't for a couple of recent
changes to the standard Emacs undo system. These are the commands ~undo-only~ and
~undo-redo~. Unlike standard ~undo~, ~undo-only~ will not undo undos and ~undo-redo~
will /only/ undo undos and not record itself as something to be undone. This might sound
a bit confusing, but you can think of ~undo-only~ and ~undo-redo~ as exposing just the
"normal" linear undo that most editors would provide.

I now have the following ~vundo config~:

#+begin_src elisp
(use-package vundo
  :bind (("C-x u" . vundo)
         ("C-/" . undo-only)
         ("C-?" . undo-redo))
  :config
  (setq vundo-glyph-alist vundo-ascii-symbols))
#+end_src

To get persistent undo (ie. saving the undo history across Emacs sessions) there is
[[https://github.com/emacsmirror/undo-fu-session][undo-fu-session]].

With this setup you get what undo-tree provided: the simple undo/redo system most of the
time and access to the full tree when you need it. But because it uses the standard
Emacs undo system it is simpler, potentially more robust and you get to use one of the
most powerful Emacs undo features of all, as we will see next.

** Undo in region

We've now covered problem number 1, but what about 2? A tragically little-known feature
of the Emacs undo system is undo in region. Quite simply, if you select a region and
undo, it will undo only within that region! How cool is that?

Undo-tree does support this, but it must be enabled by setting
~undo-tree-enable-undo-in-region~. However, it is known to be buggy and the undo-tree
author recommends against its use. But if we use vundo we can use it just fine.

** Conclusion

The default Emacs undo system is the best there is. It's one of the many small things
that mean Emacs users never want to leave Emacs. Not only does it let you recover any
previous state, you can even restrict your undoing to portions of the whole buffer.

But it wouldn't really be Emacs if we didn't still try to improve things. With just a
couple of tweaks and a couple of extra packages we get an undo system that is easy to
understand while losing none of its power and fully persistent between Emacs sessions.

Happy hacking!

* DONE Bash History Hacks                                 :bash:linux:direnv:
CLOSED: [2023-12-05 Tue 22:22]
:PROPERTIES:
:EXPORT_FILE_NAME: project-local-bash-history
:END:

** Introduction                                                      :ignore:

When you work a lot on the command line, history can be invaluable. I've lost count of
the number of times I've forgotten how I ran some earlier command and used my bash
history to find out what it was. This is one of the big advantages of using CLIs over
GUIs.

** Accessing history

The main interface I use to my history is ~^P~ (~Ctrl-P~). This recalls the previous
command from history. Subsequent presses step further back and ~^N~ steps forward
again. These keys are set in muscle memory at this point, I use them that much (they
also work in emacs and many other places).

A really useful extension to that is ~^R~. This does a reverse incremental search
through your history for whatever you type. Subsequent presses of ~^R~ go further
back. I do this many times each day and cringe when I see people stepping up further
than a few ~^P~ through history.

You can also use ~^S~ to search forwards again (so the counterpart to ~^N~), but you
probably need to add the following option in your ~.bashrc~ first:[fn:7]

#+begin_src bash
stty -ixon
#+end_src

Then there is searching through history with something like ~history | grep <cmd>~ but
sometimes I just do ~history~ and have a look around. You could, of course, pipe your
history anywhere else like into ~sed~ and ~uniq~ to perform some kind of stats on your
history.

I like to set the following to enable a nicer timestamp when viewing history:

#+begin_src bash
HISTTIMEFORMAT="[%F %T] "
#+end_src

Now let's look at some tweaks to help with collecting and curating said history.

[fn:7] See: https://unix.stackexchange.com/questions/73498/how-to-cycle-through-reverse-i-search-in-bash

** Unlimited history

The first thing to enable is an unlimited history file. You have the disk space. Put the
following options in your ~.bashrc~ file:

#+begin_src bash
HISTFILESIZE=
HISTSIZE=
shopt -s histappend
#+end_src

You should search any existing ~.bashrc~ file for these options as many distros include
them set by default.

At this point it's useful to understand how bash history works. First there is the
history we were interacting with above via ~^P~ and ~history~ etc. This is stored in
memory and local to each bash instance. When you type new commands, this is where they
end up. Then, separately, there is a persistent history file which is stored on
disk. You can find out where yours will be by checking the variable ~HISTFILE~ (it's
usually something like ~~/.bash_history~).

By default, when you run ~bash~ it truncates your history file to ~HISTFILESIZE~ then
reads it into memory. When you exit it overwrites your history file with ~HISTSIZE~
entries from memory. With these variables unset the limits are removed, but you still
need to enable ~histappend~ so bash /appends/ to the history file instead of overwriting
it. Otherwise you'll get history loss when you run multiple shells.

I also set the following option:

#+begin_src bash
export HISTCONTROL=ignoreboth
#+end_src

This ignores duplicate lines and lines that start with a space, so if you are going to
include a password or something you can start the line with a space to stop it getting
into your history.

** Project-local history

Sometimes when I'm exploring some new data or tools it seems appropriate to keep history
local to that project only. This gives me an informal log of what I've done to get the
data files in my working directory. This can be especially useful if you later need to
formalise things for writing a paper, for example.

What we'd like is when we ~cd~ to a project any in-memory history is written out to the
current/old history file, then switch to a project-specific history file, clear the
in-memory history and read in the project-specific history file.

For this I wondered if I could use [[https://direnv.net/][direnv]] which is a great tool for setting
project-specific environment variables. But unfortunately direnv can /only/ set
environment variables.[fn:6] If we simply set ~HISTFILE~ in the ~.envrc~ file this won't
have the desired effect because, as mentioned above, bash only reads the history file
when it opens and writes it when it exits. We need to also interact with the ~history~
command directly to control writing/reading to the old/new history files.

Fortunately, someone else wondered if they could do this with direnv and posted a
solution to the GitHub issue board using a bash function:
https://github.com/direnv/direnv/issues/1062

I have tweaked the solution slightly and come up with the following:

#+begin_src bash
_set_local_histfile() {
    history -a

    if [[ -n $DIRENV_FILE ]] && [[ -n $LOCAL_HISTFILE ]]; then
        local histfile_local=${HOME}/.bash_history.d/${DIRENV_FILE%\/*}
        mkdir -p $(dirname $histfile_local)
        touch $histfile_local
        chmod 600 $histfile_local
    else
        local histfile_local=${HOME}/.bash_history
    fi

    [[ "$HISTFILE" == "$histfile_local" ]] && return

    # switch history to new file
    echo "Writing Bash history to $histfile_local"

    history -w
    history -c

    export HISTFILE=$histfile_local

    history -r
}

PROMPT_COMMAND="_set_local_histfile;$PROMPT_COMMAND"
#+end_src

The function ~_set_local_histfile~ runs before/after each command you run. The first
thing it does is instantly appends the current history to the history file (~history
-a~). Then it checks to see if we have enabled local history and, if so, makes a new
history file in your home directory under ~.bash_history.d~. I wanted to keep all
history in my home directory rather than in the project directory just in case the
project is on an NFS mount or something and I can't or wouldn't want to write history
there. It's also important to set a strict access control on history files (in case you
type passwords or something). Then, if a local history file is in use, we write out the
current history, clear current history, switch file and read the new history file, as
laid out above.

Finally, I chose to make this an option rather than setting it whenever a ~.envrc~ file
is in use, so to use this set ~LOCAL_HISTFILE=1~ in ~.envrc~:

#+begin_src bash
echo 'export LOCAL_HISTFILE=1' >> .envrc
#+end_src

Or to make it a tiny bit nicer you can define a command in your ~.direnvrc~:

#+begin_src bash
use_localhist() {
    export LOCAL_HISTFILE=1
}
#+end_src

Then you can use simply ~use localhist~ in an ~.envrc~.

[fn:6] Direnv does not run the ~.envrc~ file in the current shell but in a subshell and
then inspects changes to the environment in the subshell.

** Conclusion

Learning to use history can really improve your proficiency on the command line and with
a few simple tweaks in your ~.bashrc~ it becomes even more useful and, sometimes, a
lifesaver.

Increasing the size of your history and preventing history loss is the kind of thing
you'll wish you enabled yesterday, so you might as well do it now. The local history one
is a bit more niche, but can be very useful for people like scientists doing a lot of ad
hoc data processing on the command line.

* DONE Using Nerd Icons in Org Agenda                         :emacs:orgmode:
CLOSED: [2023-11-14 Tue 23:56]
:PROPERTIES:
:EXPORT_FILE_NAME: org-agenda-nerd-icons
:END:

** Introduction                                                      :ignore:

Org mode supports icons in its agenda views.  The icons can be given as either file
paths to images (like SVGs), as image data or as a display property.  I use a [[https://www.nerdfonts.com/][Nerd Font]]
along with the [[https://github.com/rainstormstudio/nerd-icons.el][nerd-icons]] package in my Emacs config, so I thought I might as well
enable icons in my org agenda views.

[[file:/emacs/org-agenda-icons.png]]

The nice thing about using nerd fonts is this works perfectly in text mode too (assuming
you have a nerd font configured for your terminal emulator).

** The code

Since the nerd icons are accessible through a few different sets, I first wrote a
function to convert a "simple" alist icon specification into an alist org-mode expects:

#+begin_src elisp
(defun gk-nerd-agenda-icons (fun prefix alist)
  "Makes an org agenda alist"
  (mapcar (pcase-lambda (`(,category . ,icon))
            `(,category
              (,(funcall fun (concat prefix icon) :height 1.0))))
          alist))
#+end_src

I use this function like so to create my mapping from categories to icons:

#+begin_src elisp
(setq org-agenda-category-icon-alist
      (append
       (gk-nerd-agenda-icons #'nerd-icons-mdicon "nf-md-"
                             '(("Birthday" . "cake_variant")
                               ("Diary" . "book_clock")
                               ("Holiday" . "umbrella_beach")
                               ("Chore" . "broom")
                               ("Regular" . "autorenew")
                               ("Sprint" . "run_fast")
                               ("Database" . "database")
                               ("ELT" . "pipe")
                               ("Devops" . "gitlab")
                               ("Blog" . "fountain_pen_tip")
                               ("FOSS" . "code_braces")
                               ("Tool" . "tools")
                               ("Todo" . "list_status")))
       (gk-nerd-agenda-icons #'nerd-icons-sucicon "nf-custom-"
                             '(("Emacs" . "emacs")
                               ("Org" . "orgmode")))
       '(("" '(space . (:width (11)))))))
#+end_src

The final entry is a default match and puts a space of 11 pixels when the category
doesn't match any entry in the list. You'll have to play around with the number of
pixels here as it depends on your font.

You can adjust the ~:height 1.0~ part to make the icons bigger or smaller in a graphical
emacs. You'll have to experiment with this and it will depend on the font you use.

The final thing you probably need is a modification to ~org-agenda-prefix-format~.  The
reason this is necessary is because some icons take up too much space and make the lines
in the agenda overflow on the right. This will depend on your font also, but to fix
overflowing lines, make sure your ~org-agenda-prefix-format~ entries include
~%-2i~. This means org will include two characters for the icon in its calculation of
line width.

#+begin_src elisp
(setq org-agenda-prefix-format '((agenda . " %-2i %-12:c%?-12t% s")
                                 (todo .   " %-2i %-12:c")
                                 (tags .   " %-2i %-12:c")
                                 (search . " %-2i %-12:c")))
#+end_src

You can, of course, remove the category text (~%-12:c~) completely now, if you wish.

** Limitations

This is actually a bit of a hack as what org agenda is actually doing here is using our
options as a display property passed to ~propertize~.  It works because a display
property can be a string, which is just displayed in place of whatever is being
"propertized".

Unfortunately this means there are some limitations: you can't apply other display
properties, nor are recursive display properties supported (ie. using ~(propertize icon
...)~ /as/ the display property). So there can be some alignment issues and you can't
change the colours of the icons.

Perhaps it's possible to patch to org-mode to properly support propertized text as the
icon. The difficulty might be making it backwards compatible with current behaviour.

Before I do that I'll see if I actually enjoy using icons enough over the next few
weeks...

** Alternative approach

An equally hacky, but much easier, way is just setting the category in your org files to
the nerd icon:

#+begin_src org
,* Database                                                            :@work:
:PROPERTIES:
:CATEGORY: 󰆼
:END:
#+end_src

Then something like:

#+begin_src elisp
(setq org-agenda-prefix-format '((agenda . " %-2c%?-12t% s")
                                 (todo .   " %-2c")
                                 (tags .   " %-2c")
                                 (search . " %-2c")))
#+end_src

This means you can't practically use the categories for filters and stuff, though.

Happy hacking!

* TODO Git is your Safety Rope                          :git:vcs:development:
:PROPERTIES:
:EXPORT_FILE_NAME: git-safety-rope
:END:

** Introduction                                                      :ignore:

When I was learning rock climbing I distinctly remember my instructor telling me "you'll
never get good until you learn to trust the rope".

This principle seems to ring true in many areas of life.  You'll never really push
yourself if you think there's a high chance of a catastrophe.  That's why we have things
like insurance, backups and, well, safety ropes.

But wait, isn't git the thing I need protecting from?  Like any powerful tool, git can
do the wrong thing if wielded incorrectly.  But if you follow just a few simple rules,
it's literally impossible for git to break anything.

** Version control without git

A version control system allows you to store and access multiple version of the same
codebase.  It's worth imagining what this might look like without git, so let's invent
our own version control.

First let's make our project and create a README:

#+begin_src bash
mkdir my-project
echo "hi" > my-project/README
#+end_src

This is a pretty good start, so let's *commit* this version:

#+begin_src bash
cd ..
cp -pr my-project my-project-v1
#+end_src

An important rule in our system is that we must never touch any committed version again.
But we continue to work on the original copy.  This copy is known as the *working
directory*.

So we make another change:

#+begin_src bash
echo "more stuff" >> my-project/README
echo "new file stuff" >> my-project/new-file
#+end_src

Let's check what the difference is compared to v1:

#+begin_src bash
diff -Nur my-project-v1 my-project
#+end_src

#+begin_src diff
diff -Nur my-project-v1/new-file my-project/new-file
--- my-project-v1/new-file	1970-01-01 01:00:00.000000000 +0100
+++ my-project/new-file	2023-09-12 22:53:23.421997103 +0100
@@ -0,0 +1 @@
+new file stuff
diff -Nur my-project-v1/README my-project/README
--- my-project-v1/README	2023-09-12 22:52:44.806065953 +0100
+++ my-project/README	2023-09-12 22:53:13.246015242 +0100
@@ -1 +1,2 @@
 hi
+more stuff
#+end_src

Let's commit this new version:

#+begin_src bash
cp -pr my-project my-project-v1-1
#+end_src

Notice we called it ~v1-1~ instead of ~v2~.  This means it's the first version descended
from ~v1~.  To see why this is important, let's first check out ~v1~ again:

#+begin_src bash
rsync -a --delete my-project-v1/ my-project/
#+end_src

Now we make a completely different change:

#+begin_src bash
echo "something different" >> my-project/README
#+end_src

Remember we can always check the diff:

#+begin_src bash
diff -Nur my-project-v1 my-project
#+end_src

#+begin_src diff
diff -Nur my-project-v1/README my-project/README
--- my-project-v1/README	2023-09-12 22:52:44.806065953 +0100
+++ my-project/README	2023-09-12 23:14:10.060730295 +0100
@@ -1 +1,2 @@
 hi
+something different
#+end_src

And now we can commit this version, which is the second version descended from ~v1~:

#+begin_src bash
cp -pr my-project my-project-v1-2
#+end_src

We now have two branches that diverge at ~v1~.

OK, you probably get the idea.  This is basically how git works, The difference is git
makes it possible (and efficient) to have literally /millions/ of versions of the same
codebase on your filesystem.  But it's essentially doing the same thing behind the
scenes: making copies and storing the parent/child relationships between copies.

** You can't touch the blob store

In our version control system we had the rule that we would never touch any committed
version again.  Git has the very same rule.  Git stores all the committed versions in
its blob store and the blob store is an *immutable, append-only database*.

This is possibly the most fundamental thing to understand about git.  It will not ever
delete things from the blob store[fn:1]. So this is the key: to not lose anything you
need to get it into the blob store.  Your working directory is /not/ in the blob store.
To get stuff into the blob store, you need to commit it.

TODO:

- Commands that can corrupt worktree: ~git reset --hard~
- ~git worktree~ to make a new worktree
- push can affect other people so be careful and responsible

[fn:1] OK, "not ever" is a lie.  Git does actually delete unreachable items from its
blob store, but this is mainly stuff created by internal operations.  The process is
called garbage collection.  In practice this doesn't matter because you can't
practically get at those blobs anyway, but it does also prune the reflog, removing
anything older than 90 days, by default.  This is a bit less good but, again, in
practice 90 days is probably more than long enough.

* TODO Calendars                                               :calendar:gui:
:PROPERTIES:
:EXPORT_FILE_NAME: calendars
:END:

Why are we still using paper-like calendars?

Bit about Gutenberg press.

HN comments:

Thunderbird has the only calendar I know that has a "multiweek" display as opposed to
(well, in addition to) the utterly retarded month view that exists in every other GUI.

We've been doing electronic calendars for how long now? Why are we still using a
paradigm from paper based calendars? At the beginning of a month I can see three weeks
ahead, but at the end of the month I can see three weeks behind. It frustrates me no end
that this is still a thing. It reminds me of the early days of Google maps when they
were no better than paper maps, but now we can rotate the map, zoom in and out etc. But
calendars are still no better than paper calendars. Apart from the one in Thunderbird.

---

It did have zoom, but they were fixed levels so no different to having multiple paper
maps at different scales. Yes, of course there is the advantage that it's "not paper",
but that was the only advantage really. This is not unexpected at all as new technology
very often mimics existing technology in its first iteration. If you look at the first
outputs of the Gutenberg press you can see they were trying to mimic handwritten books
of the time. But usually the new technology very quickly surpasses the old after the
first iteration, as electronic maps have now done.

* DONE Custom Static Vector Maps on your Hugo Static Site    :hugo:blog:maps:
CLOSED: [2023-10-27 Fri 00:11]
:PROPERTIES:
:EXPORT_FILE_NAME: hugo-static-site-maps
:EXPORT_HUGO_LASTMOD: [2023-10-30 Mon 22:52]
:END:

** Introduction                                                     :ignore:

This blog is a static site built with [[https://gohugo.io/][Hugo]].  Being static means it can be served from a
basic, standard (you might say /stupid/) web server with no server-side scripting at
all.  In fact, this blog is currently hosted on Github Pages, but it could be anywhere.

Up until now, if you wanted to include an interactive map on a static site you were
limited to using an external service like Google Maps or Mapbox and embedding their JS
into your page.  This would then call to their non-static backend service to produce
some kind of tiles for your frontend.

But we can now put truly static maps into a static site.  Behold!

#+hugo: {{<map tiles-url="/bangor.osm.pmtiles" bounds="-4.178753,53.215670,-4.137597,53.231163" max-bounds="-4.199352,53.210916,-4.116955,53.235941">}}

This isn't coming from a backend tile server.  This is all completely static, it's all
hosted on GitHub Pages and the above map uses less than 2 MiB of storage.  What's more
it's really quite easy to get started.  Let's see how it's done.

Although I'm using Hugo as a concrete example below, all of this should be easily
translatable to any static site.

** Generating a PMTiles basemap

The magic here starts with [[https://protomaps.com/][Protomaps]] and the PMTiles format.  PMTiles is an archive
format for tile data which is designed to be accessed with HTTP range requests.  As long
as the backend server supports HTTP range requests[fn:2] then the client can figure out
which requests to make to get the tiles it needs.

This means our map data can be hosted anywhere, just like our static site.

You can create a PMTiles archive from raw map data (such as OpenStreetMap), but the
easiest way is to extract data from an existing archive.  The Protomaps project produces
[[https://maps.protomaps.com/builds/][daily builds]] of the entire world from OSM data.  These files are over 100 GiB but you can
extract a much smaller file without downloading the whole thing.

First download the latest release of go-pmtiles from [[https://github.com/protomaps/go-pmtiles/releases][GitHub]] for your platform and
extract it somewhere (preferably somewhere on your ~PATH~ like perhaps ~~/.local/bin~).

Next you need to calculate a bounding box for your extract.  I used [[http://bboxfinder.com][bboxfinder.com]].
Draw a rectangle then copy the *box* at the bottom.  It should look something like
~-16.273499,27.508271,-14.889221,28.386568~.

Make sure you keep a note of this bounding box for later!

Now, using ~pmtiles~ that you just installed, you can create your extract like so:

#+begin_src bash
pmtiles extract \
        https://build.protomaps.com/20231001.pmtiles \
        mymap.pmtiles \
        --bbox=-16.273499,27.508271,-14.889221,28.386568
#+end_src

You can test your basemap by visiting [[https://protomaps.github.io/PMTiles/]] and selecting
your newly created pmtiles file.

Finally, put your PMTiles file into your Hugo static directory, for example
~static/mymap.pmtiles~.

[fn:2] Most do, but not all. Notably I found the dev server used by the [[https://parceljs.org/][Parcel]] bundler
does not, which led to much head scratching.

** MapLibre GL

Now you have a PMTiles extract you're happy with we need to render it somehow.  For this
we can use [[https://github.com/maplibre/maplibre-gl-js][maplibre-gl]].

If you haven't already, in your Hugo project directory initialise an npm project:

#+begin_src bash
npm init
#+end_src

Now install the required packages:

#+begin_src bash
npm install pmtiles
npm install maplibre-gl
npm install protomaps-themes-base
#+end_src

Now add the following as a JavaScript asset at ~assets/js/map.js~:

#+begin_src js
import * as pmtiles from "pmtiles";
import * as maplibregl from "maplibre-gl";
import layers from 'protomaps-themes-base';

let protocol = new pmtiles.Protocol();
maplibregl.addProtocol("pmtiles",protocol.tile);

function makeMap({tilesUrl, bounds, maxBounds, container = "map"}) {
    var map = new maplibregl.Map({
        container: container,
        style: {
            version: 8,
            glyphs: 'https://cdn.protomaps.com/fonts/pbf/{fontstack}/{range}.pbf',
            sources: {
                "protomaps": {
                    type: "vector",
                    url: `pmtiles://${tilesUrl}`,
                    attribution: '<a href="https://protomaps.com">Protomaps</a> © <a href="https://openstreetmap.org">OpenStreetMap</a>'
                }
            },
            layers: layers("protomaps","light")
        },
        bounds: bounds,
        maxBounds: maxBounds,
    });
    return map;
}

document.addEventListener('DOMContentLoaded', function(){
    document.querySelectorAll("div.map").forEach((e) => {
        makeMap({
            tilesUrl: e.dataset.tilesUrl,
            bounds: e.dataset.bounds.split(",").map(parseFloat),
            maxBounds: e.dataset.maxBounds.split(",").map(parseFloat),
            container: e,
        });
    });
});
#+end_src

What this does is finds every ~div~ on your page with the class ~map~ and creates a
maplibre-gl map there.  It expects the ~div.map~ elements to have data attributes which
it uses to set up the map.  Each ~div~ should look like this:

#+begin_src html
<div class="map"
     data-tiles-url="mymap.pmtiles"
     data-bounds="-16.273499,27.508271,-14.889221,28.386568"
     data-max-bounds="-16.273499,27.508271,-14.889221,28.386568"
</div>
#+end_src

The bounds are what you saved earlier from running ~pmtiles~.  You should definitely set
~max-bounds~ the same as your original bbox, but you can set ~bounds~ smaller, like I
have (bounds is the default zoom, maxBounds is the maximum span of the map).

Now let's put it all together with Hugo.

** Building with Hugo

This section is quite dependent on your site and theme set up, so I can't give
specifics, but I hope you already have an idea of where to put CSS or JavaScript etc.
Some themes include provision for an ~extra-head.html~ or similar that you can put in
~layouts/partials~.[fn:3]

*** JavaScript bundle

Most of the work will be done by the JavaScript above, but we first need to bundle and
include it in our pages.  This is done using Hugo Pipes.[fn:4]  Put the following in the
~<head>~ section of your site, near other scripts:

#+begin_src html
{{ $jsBundle := resources.Get "js/map.js" | js.Build "js/mapbundle.js" | minify | fingerprint }}
<script defer src="{{ $jsBundle.Permalink }}" integrity="{{ $jsBundle.Data.Integrity }}"></script>
#+end_src

*** CSS

You'll need a couple of bits of CSS, first we need to style the ~div.map~ elements with
some sensible default at least, so add the following to a style sheet:

#+begin_src css
div.map {
    width: 100%;
    height: 500px;
    margin-bottom: 1rem;
}
#+end_src

You also need maplibgre-gl's style.  First mount the stylesheet from ~node_modules~ in
Hugo's ~assets~ by adding to your Hugo config:

#+begin_src yaml
module:
  mounts:
    - source: "assets"
      target: "assets"
    - source: "node_modules/maplibre-gl/dist/maplibre-gl.css"
      target: "assets/css/maplibre-gl.css"
#+end_src

Do not forget the default mount for ~assets~.  Now in your ~<head>~ section add the
stylesheet:

#+begin_src html
{{ $style := resources.Get "css/maplibre-gl.css" | fingerprint }}
<link rel="stylesheet" href="{{ $style.Permalink }}">
#+end_src

*** Hugo shortcode

To insert the ~div.map~ element into your markdown posts you'll need a shortcode.  Put
the following in ~layouts/shortcodes/map.html~:

#+begin_src html
<div class="map"
     data-tiles-url="{{ .Get "tiles-url" }}"
     data-bounds="{{ .Get "bounds" }}"
     data-max-bounds="{{ .Get "max-bounds" }}">
</div>
#+end_src

Now you can simply use the shortcode anywhere in your site like so:

#+begin_src markdown
{{</*map tiles-url="/gran-canaria2.pmtiles" bounds="-15.923996,27.713926,-15.308075,28.205793" max-bounds="-16.273499,27.508271,-14.889221,28.386568"*/>}}
#+end_src

[fn:3] Overriding a theme is quite easy with Hugo, see:
[[https://bwaycer.github.io/hugo_tutorial.hugo/themes/customizing/]]

[fn:4] If you are unfamiliar with Hugo Pipes you can read all about it [[https://www.regisphilibert.com/blog/2018/07/hugo-pipes-and-asset-processing-pipeline/][here]].

** Conclusion

I can't believe how easy this has been for me to set up.  Here's to [[https://protomaps.com/][Protomaps]], [[https://maplibre.org/][MapLibre
GL]] and, of course, [[https://www.openstreetmap.org/][OpenStreetMap]]!

I had previously tried setting up my own custom maps and found it quite difficult to
get started, not to mention requiring me to run a special tileserver somewhere or use a
third party service.  I'm by no means a map expert (although I am an OpenStreetMap
contributor of many years, if that means anything), so I find this post a testament to
how far the work of the free/open mapping community has come.

Of course, this approach isn't suitable for everything and comes with drawbacks.  In
particular, your map will never receive updates unless you update the pmtiles file.
This could be particularly bad if your area doesn't have good OpenStreetMap coverage.

But, for me, this is static by design.  I /want/ these pages to be static, including the
map.  If I include a route showing where I walked, it doesn't make sense for it to
appear on some map of the future.  It /should/ be a map of the past.

Also, let's not forget that maps don't have to contain "real" data.  It could contain a
planned development or even just a fantasy world.  There are many possibilities.  Next
on my list to play is to try to get hillshading/relief into my maps.

To finish, just for fun, here's another map showing a recent multi-day walk across Gran
Canaria[fn:5]:

#+hugo: {{<map tiles-url="/gran-canaria.osm.pmtiles" relief-url="/gran-canaria-relief.pmtiles" tracks="/gc1.gpx,/gc2.gpx,/gc3.gpx,/gc4.gpx" bounds="-15.923996,27.713926,-15.308075,28.205793" max-bounds="-16.273499,27.508271,-14.889221,28.386568">}}

[fn:5] I've used [[https://github.com/jimmyrocks/maplibre-gl-vector-text-protocol][maplibre-gl-vector-text-protocol]] to add statically hosted GPX files to
the map.  See the [[https://github.com/georgek/blog][source]] of my blog to see how.

** Appendix

*** org-mode and ox-hugo

I don't write my blog in Markdown directly, but in org-mode first and use ox-hugo to
export it.  There are a [[https://ox-hugo.scripter.co/doc/shortcodes/][few]] ways to add shortcodes, but the neatest I've found for the
map shortcodes is simply:

#+begin_src org
,#+hugo: {{<map tiles-url="/bangor.pmtiles" bounds="-4.178753,53.215670,-4.137597,53.231163" max-bounds="-4.199352,53.210916,-4.116955,53.235941">}}
#+end_src

* DONE Why is Emacs Hanging?                                :emacs:debugging:
CLOSED: [2023-09-21 Thu 14:10]
:PROPERTIES:
:EXPORT_FILE_NAME: emacs-hangs-debug
:END:

Even after using Emacs for 15 years there's still so much I can learn. I probably should
have already known this, but there's a first time for everything.

It's rare that Emacs hangs. Exceedingly rare. Which is probably why I didn't know how to
deal with it. Today Emacs started hanging when trying to open files over a remote TRAMP
session (SSH).

The most important key of all that everyone who uses Emacs knows is ~C-g~. This is the
universal "quit" key and it has the power to interrupt any long running processes. What
I didn't know about is ~M-x toggle-debug-on-quit~. I've used ~toggle-debug-on-error~
extensively when programming Elisp (I even have it bound to a key in Elisp
buffers). ~toggle-debug-on-quit~ is similar except the debugger is invoked when you
~C-g~.

While this is enabled, I was able to reproduce the hang, then press ~C-g~. I could see
that what was happening is ~ess-r-package-auto-activate~ was being called via
~after-change-major-mode-hook~, this was in turn calling on TRAMP again to try to find
an R package or something. I don't regularly use ESS mode, so I simply disabled this
behaviour with ~(setq ess-r-package-auto-activate nil)~.

~toggle-debug-on-quit~ should be toggled off again aftewards, as quitting isn't actually
an error most of the time. Doom modeline handily displays an icon when it's enabled,
confirming that I'm the last person to know about this.

Something else interesting to consider here is packages can still affect Emacs
performance even if you aren't using them. I haven't used R or ESS mode for years, but
I've left them in my config because, why not? But these "dormant" packages can still be
impacting performance and it might be worth auditing hooks like
~after-change-major-mode-hook~ to check for packages you don't really need any more.

* DONE Replacing Strings in an Entire Project                  :emacs:regexp:
CLOSED: [2023-08-22 Tue 14:22]
:PROPERTIES:
:EXPORT_FILE_NAME: emacs-regexp-replace
:END:

This is a little trick I just applied and thought was cool enough to write down.

Let's say you want to replace a name that is used throughout a project.  Due to various
conventions/restrictions in use the name might appear in several forms like:
~MY_COOL_NAME~, ~my-cool-name~, ~my_cool_name~ etc.

In Emacs you can invoke regexp replace across an entire project by invoking
~project-query-replace-regexp~, by default bound to ~C-x p r~.  This will first prompt
for the regexp to search for, then what to replace it with.

For the search regexp we can put: ~my\([_-]\)cool\1name~.

This allows either underscore or hyphen as a separator.  Notice we use ~\1~ as the
second separator.  This is a "backreference" and simply refers to whatever was captured
in the first group, in this case ~\([_-]\)~.

We can then us the same backreference in the replacement, so we can put: ~new\1name~.

After pressing enter again emacs will then cycle through every replacement in every file
in the project allowing you to either apply it, with ~y~ or skip it, with ~n~.  If you
wish to make the changes across an entire file unconditionally, press ~!~.  If you wish
to skip an entire file, press ~N~.  You can also press ~?~ to see the other options.

Notice Emacs does what you (probably) want when it comes to case.  We didn't type the
search in upper case, but it will match ~MY_COOL_NAME~ and replace it with ~NEW_NAME~.
Similarly, if there were a ~My-Cool-Name~, it would replace it with ~New-Name~
automatically.

* DONE Install Calibre without Root                     :calibre:ebook:linux:
CLOSED: [2023-08-13 Sun 13:23]
:PROPERTIES:
:EXPORT_FILE_NAME: calibre-rootless-install
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :summary How to install Calibre on Linux without root and/or sudo
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :description The best way to install Calibre on Linux
:END:

** Introduction                                                      :ignore:

On Linux, software should generally be installed with your system package manager (apt,
yum, portage etc.)  However, Calibre is a bit "special" in this respect.  While
well-loved, it's known to be a bit difficult to package (to say the least) and most
distro packages you'll find are out of date.  The [[https://calibre-ebook.com/download_linux][official website]] recommends against
using any distro packages and instead installing it directly from the site.

Unfortunately, the official instructions are problematic for a number of reasons.  For a
start, copying and pasting commands from the browser is considered dangerous.  But
that's easy to fix, in bash do ~Ctrl-X Ctrl-E~ and your preferred text editor will be
opened for you to type your command.  This means you can inspect what is pasted before
is run (save the file then exit the editor to run the command).  Very important.  Always
do this when copy/pasting from the web.

But that's not all, it also has you run the installer as root.  The installer does tuck
everything nicely away inside ~/opt/calibre~, but it's just not a good idea for many
reasons.

** User-level installation

Instead you can install it in your home directory under ~~/opt~ like this:

#+begin_src bash
wget -nv -O- https://download.calibre-ebook.com/linux-installer.sh \
    | sh /dev/stdin install_dir=~/opt isolated=True
#+end_src

Or, even better, as a completely different user so any error in the script can't trample
anything in your home directory:

#+begin_src bash
sudo useradd calibre            # add new user the first time

wget -nv -O- https://download.calibre-ebook.com/linux-installer.sh \
    | sudo -u calibre sh -s install_dir=~calibre/opt isolated=True
#+end_src

Once finished it will tell you to run ~/home/<user>/opt/calibre/calibre~ to start.  If
you have ~~/bin~ (or perhaps ~~/.local/bin~) on your ~PATH~ you can add a nicer link
with the following:

#+begin_src bash
ln -s /home/<user>/opt/calibre/calibre ~/bin
#+end_src

Then you should be able to run simply ~calibre~.

** Desktop environment integration

If you need a menu item in a desktop environment then you might first need to add the
link to ~/usr/bin~ (this also makes it available for all users):

#+begin_src bash
sudo ln -s /home/calibre/opt/calibre/calibre /usr/bin/calibre
#+end_src

Then you need to make a desktop file called
~/usr/share/applications/calibre-gui.desktop~ with the following:

#+begin_src bash
[Desktop Entry]
Version=1.0
Type=Application
Name=calibre
GenericName=E-book library management
Comment=E-book library management: Convert, view, share, catalogue all your e-books
TryExec=calibre
Exec=calibre --detach %U
Icon=calibre-gui
Categories=Office;
X-GNOME-UsesNotifications=true
MimeType=image/vnd.djvu;application/x-cb7;application/oebps-package+xml;application/epub+zip;application/x-mobi8-ebook;text/plain;application/x-cbc;application/xhtml+xml;application/x-cbz;application/ereader;application/pdf;text/fb2+xml;application/x-mobipocket-subscription;application/x-cbr;application/x-sony-bbeb;text/x-markdown;text/html;application/vnd.oasis.opendocument.text;application/x-mobipocket-ebook;application/vnd.ms-word.document.macroenabled.12;application/vnd.openxmlformats-officedocument.wordprocessingml.document;text/rtf;x-scheme-handler/calibre;
#+end_src

You only need to make these links and desktop entry once.  Next time you update Calibre
they will point to the new version.

* DONE Writing a Blog with Org-mode             :emacs:orgmode:hugo:blog:gui:
CLOSED: [2023-07-15 Sat 13:43]
:PROPERTIES:
:EXPORT_FILE_NAME: hugo-org-mode
:EXPORT_HUGO_LASTMOD: <2023-10-08 Sun 20:52>
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :summary I've set up my blog such that I can write it using org-mode and host it and edit it anywhere. I'm using Hugo as a static site generator and GitHub as a host.
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :description How I set up this blog using emacs, org-mode and Hugo
:END:

** Introduction                                                      :ignore:

I've always thought I should write a blog, but I just never got around to setting it
up.  I know there are services you can simply sign up to and start writing, but that
isn't for me.  I have two requirements for this thing:

1. I can write using tools of my choice,
2. I can host it anywhere.

My tool of choice for writing anything is emacs and, for natural language in particular,
[[https://orgmode.org/][org-mode]].  This is a bit like markdown, but better.  For version control and deployment
I use git.

I also want to be able to host it anywhere because I don't want to be tied to a host
and, ideally, I don't want to pay for it either.  Back in the day it was common to use a
dynamic site for a blog.  Your content would live in a database and was served up using
some backend process like WordPress.  But that's too expensive and places too many
requirements on the host.

With that in mind, I've decided to use a static site generator.  This is ideal as it
means I don't have to write raw HTML myself (although you can) but the output can be
hosted anywhere.  I've decided to use [[https://gohugo.io/][Hugo]] simply because it looks good, seems fast,
well maintained, supports the workflow I want and, most importantly, supports org-mode.

** Using org-mode with Hugo

First of all, you set up your Hugo project by following the [[https://gohugo.io/getting-started/quick-start/][quickstart guide]].

The next thing I did was install the [[https://github.com/adityatelange/hugo-PaperMod/wiki/Installation][PaperMod theme]], as it seems like a decent default
for a blog.

Now, to start a new page using org-mode, you first need to install an [[https://gohugo.io/content-management/archetypes/][archetype]].  These
are essentially templates that Hugo uses to start new content.  By default it comes with
a markdown archetype in ~archetypes/default.md~.  You should add the following code in
~archetypes/default.org~:

#+NAME: archetypes/default.org
#+BEGIN_SRC org
,#+TITLE: {{ replace .Name "-" " " | title }}
,#+DATE: {{ .Date }}
,#+DRAFT: true
,#+DESCRIPTION:
,#+CATEGORIES[]:
,#+TAGS[]:
,#+KEYWORDS[]:
,#+SLUG:
,#+SUMMARY:

#+END_SRC

Now you can start a new org-mode post by running: ~hugo new posts/my-org-post.org~.
You'll find your org-mode file ready to edit in ~content/posts/my-org-post.org~.  The
metadata is pretty self-explanatory, but you can just play around with it.

** Deploying with Github Actions

First of all, *before* you build or commit anything, add a ~.gitignore~ file:

#+BEGIN_SRC
/.hugo_build.lock
/public/*
!/public/.nojekyll
#+END_SRC

This will ensure you don't accidentally commit your locally built version of the site.

You should also add the ~.nojekyll~ file to stop GitHub trying to run Jekyll (another
static site generator) on your stuff.  I'm not sure if this is still necessary but it
can't harm:

#+BEGIN_SRC bash
mkdir -p public
touch public/.nojekyll
#+END_SRC

Now commit the ~.gitignore~ and ~.nojekyll~ files.

To publish your site you simply run ~hugo~.  This builds the site, including all
articles that are *not* marked as draft, and puts it all into the ~/public/~ directory.
Now, you could simply copy the contents of that directory to a web server of your
choice.  That's how we did it back in the day.  This is how it meets my "can host
anywhere" requirement.

But I'm lazy and I want it to be easier.  I just want the site to build and deploy when
I push my changes to git.  This is actually remarkably simple to achieve with modern CI
tooling such as GitHub Actions.  Although, note: I won't be tied to GitHub or GitHub
Actions in any meaningful way, it's essentially a glorified copy at the end of the day
and I can always build my site on my own computer and copy the output the
"old-fashioned" way.

To build using GitHub simply add the following to ~/.github/workflows/hugo.yml~:

#+BEGIN_SRC yaml
name: hugo

on:
  push:
    branches: [master]

permissions:
  contents: write

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          submodules: true

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: '0.115.2'
          extended: true

      - name: Build
        run: hugo --minify

      - name: Deploy
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          branch: gh-pages
          folder: public
#+END_SRC

This pipeline is triggered by pushes to the ~master~ branch.  It checks out the code,
sets up Hugo with the same version that I used locally, builds using ~--minify~ (I don't
like minified pages generally, but the source is available freely so might as well save
bandwidth) and deploys it to the ~gh-pages~ branch.  Note that the source will live on
the ~master~ branch (or any other branch), the built version will end up on the
~gh-pages~ branch, which will then be deployed to Github Pages itself.

** Conclusion

This should be everything needed to get started writing a blog (or any static site) with
Hugo and hosting it on Github.  If you are reading this then I guess it worked!

Links to the tools in use:

- org-mode: https://orgmode.org/
- Hugo: https://gohugo.io/
- GitHub Pages: https://pages.github.com/
- actions-hugo: https://github.com/peaceiris/actions-hugo
- github-pages-deploy-action: https://github.com/JamesIves/github-pages-deploy-action

** Addendum

Now that I've written a few posts I've found the built-in org support of Hugo pretty
limiting.  It doesn't have first-class support like Markdown does.  Thankfully there is
the [[https://ox-hugo.scripter.co/][ox-hugo]] package which can export org-mode files to Markdown, before being read by
Hugo.

The layout for the project is a bit different as it leverages org-mode to handle tags
and categories in a nicer way, but it's mostly the same (I didn't really have to convert
my existing posts, but I did anyway).  The main difference is in how the project is
built.  The GitHub Actions pipeline contains one new entry to set up Emacs:

#+begin_src yaml
name: deploy

on: push

permissions:
  contents: write

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          submodules: true

      - name: Setup Emacs
        uses: purcell/setup-emacs@master
        with:
          version: 29.1

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: '0.118.2'
          extended: true

      - name: Build
        run: make

      - name: Deploy
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          branch: gh-pages
          folder: public
        if: github.ref == 'refs/heads/master'
#+end_src

The build step is now container within a Makefile and looks like this:

#+begin_src makefile
build:
	cd content-org && emacs --batch -Q --load ../publish.el --funcall gpk-publish-all
	hugo --minify
#+end_src

This runs Emacs in batch mode.  The file ~publish.el~ contains settings and functions
necessary for running ~ox-hugo~:

#+begin_src emacs-lisp
;;; publish.el --- publish org-mode blog                     -*- lexical-binding: t; -*-
;;; Commentary:
;;; original influence: https://github.com/NethumL/nethuml.github.io/

;;; Code:
(defconst gpk-content-files
  '("life.org"
    "networking.org"
    "programming.org"
    "software.org"
    "technology.org"
    "thoughts.org"))

;; Install packages
(require 'package)
(package-initialize)
(unless package-archive-contents
  (add-to-list 'package-archives '("nongnu" . "https://elpa.nongnu.org/nongnu/") t)
  (add-to-list 'package-archives '("melpa" . "https://melpa.org/packages/") t)
  (package-refresh-contents))
(dolist (pkg '(org-contrib ox-hugo))
  (package-install pkg))

(require 'url-methods)
(url-scheme-register-proxy "http")
(url-scheme-register-proxy "https")

(require 'org)
(require 'ox-extra)
(require 'ox-hugo)
(ox-extras-activate '(ignore-headlines))

(defun gpk-publish-all ()
  "Publish all content files"
  (message "Publishing from emacs...")
  (dolist (file gpk-content-files)
    (find-file file)
    (org-hugo-export-wim-to-md t)
    (message (format "Exported from %s" file)))
  (message "Finished exporting to markdown"))

;;; publish.el ends here
#+end_src

As you can see from the comment, this was "influenced" (ie. taken) from another blogger
and can be found [[https://nethuml.github.io/posts/2022/06/blog-setup-with-hugo-org-mode/][here]].

# Local Variables:
# org-footnote-section: nil
# End:
