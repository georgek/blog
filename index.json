[{"content":"Docker Compose is a brilliant tool for bringing up local development environments for web projects. But working with multiple projects can be a pain due to clashes. For example, all projects want to listen to port 80 (or perhaps one of the super common higher ones like 8000 etc.). This forces developers to only bring one project up at a time, or hack the compose files to change the port numbers.\nRecently I\u0026rsquo;ve found a way that makes managing these more enjoyable.\n2023-10-05 note: If this interesting to you, be sure to check out the comments about this article on Hacker News for many other ideas.\nA single project with Docker Compose I use docker compose to manage local development instances of these projects. A typical compose file for a web project might look like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # proj/compose.yaml services: db: image: \u0026#34;postgres\u0026#34; environment: POSTGRES_DB: \u0026#34;proj\u0026#34; POSTGRES_USER: \u0026#34;user\u0026#34; POSTGRES_PASSWORD: \u0026#34;pass\u0026#34; web: build: . depends_on: - \u0026#34;db\u0026#34; environment: DATABASE_URL: \u0026#34;postgres://user:pass@db/proj\u0026#34; ports: - \u0026#34;8000:80\u0026#34; Note the very last line. This is where we map port 8000 from the host to port 80 of the container such that the service can be accessed via http://127.0.0.1:8000.\nThis works quite well for a single project, but it suffers from a couple of problems if you work on multiple projects:\nIt doesn\u0026rsquo;t scale. If I want to run another project at the same time, I\u0026rsquo;ll have to use a different port number, maybe 8001, then 8002 etc.,\nWhat if that compose.yaml file is checked in as part of the project? Does the whole team have to agree on a set of port numbers to use for each project?\nUsing overrides for multiple projects Fortunately Docker Compose does have a solution for (2) in the form of the compose.override.yaml file. This file will be automatically be merged into the compose.yaml without any extra configuration.\nUnlike some other guides (including the official docs) concerning this file, I prefer to not check compose.override.yaml into version control and instead add it to the .gitignore file. Adding it to version control completely defeats the purpose of it: to allow individual developers to override the standard compose file.\nSo, with this in mind, I no longer expose any ports by default in compose.yaml because I don\u0026rsquo;t know what will be convenient for each developer. This set up might look like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # compose.yaml services: db: image: \u0026#34;postgres\u0026#34; environment: POSTGRES_DB: \u0026#34;proj\u0026#34; POSTGRES_USER: \u0026#34;user\u0026#34; POSTGRES_PASSWORD: \u0026#34;pass\u0026#34; web: build: . depends_on: - \u0026#34;db\u0026#34; environment: DATABASE_URL: \u0026#34;postgres://user:pass@db/proj\u0026#34; 1 2 3 4 5 # compose.override.yaml (to be created by each developer) services: web: ports: - \u0026#34;8000:80\u0026#34; Using Traefik So now each developer can pick their own port numbers for each project, but we can still do better than this. People aren\u0026rsquo;t good at remembering numbers. We are much better at remembering names. Traefik is a free software edge router that can be used as a simple and super easy to configure reverse-proxy in container-based set ups.\nUsing Docker, Traefik can automatically discover services to create routes to. It uses container labels to further configure these routes. The following tiny example from the docs is illustrative:\n1 2 3 4 5 6 7 8 9 10 11 12 # traefik/compose.yaml services: reverse-proxy: image: traefik:v2.10 ports: - \u0026#34;80:80\u0026#34; volumes: - /var/run/docker.sock:/var/run/docker.sock whoami: image: traefik/whoami labels: - \u0026#34;traefik.http.routers.whoami.rule=Host(`whoami.docker.localhost`)\u0026#34; This starts two containers on the same docker network. The reverse proxy listens on port 80 and forwards traffic with a host header of \u0026ldquo;whoami.docker.localhost\u0026rdquo; to the whoami service. Traefik guesses which port to send it to whoami based on the ports exposed by the container.\nIf you haven\u0026rsquo;t played with Traefik before it\u0026rsquo;s worth going through the quick-start properly now then coming back to see how we can make this work for multiple projects.\nTraefik with multiple projects This doesn\u0026rsquo;t quite solve our problem yet. We don\u0026rsquo;t want all of our various projects inside one compose file. Luckily Traefik communicates with the Docker daemon directly and doesn\u0026rsquo;t really care about the compose file, but you do need to make sure a few things are in order for this to work.\nFirstly, make a docker network especially for Traefik to communicate with other services that you want to expose, for example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # traefik/compose.yaml services: reverse-proxy: image: traefik:v2.10 restart: unless-stopped command: --api.insecure=true --providers.docker ports: - \u0026#34;80:80\u0026#34; - \u0026#34;8080:8080\u0026#34; volumes: - \u0026#34;/var/run/docker.sock:/var/run/docker.sock\u0026#34; networks: - traefik networks: traefik: attachable: true name: traefik We create the network traefik and give it the name \u0026ldquo;traefik\u0026rdquo; (otherwise docker compose would scope it by project, e.g. \u0026ldquo;traefik_traefik\u0026rdquo;). We also allow other containers to attach to this network.\nThen in our compose.override.yaml file from above, instead of mapping ports, we do the following:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # proj/compose.override.yaml services: web: labels: - \u0026#34;traefik.http.routers.proj.rule=Host(`proj.traefik.me`)\u0026#34; - \u0026#34;traefik.http.services.proj.loadbalancer.server.port=8000\u0026#34; - \u0026#34;traefik.docker.network=traefik\u0026#34; networks: - default - traefik networks: traefik: external: true Now, after bringing up first the traefik project then your web project, you should be able to browse to http://proj.traefik.me/ in your web browser.\nThere\u0026rsquo;s a few things going on here. First, we have declared the traefik network as an external network. This means compose won\u0026rsquo;t manage it, but expects it to exist (so you must start your traefik composition first). Next we override the networks setting of web to make it part of the traefik network too. Note we also have to add the default network, otherwise it wouldn\u0026rsquo;t be able to communicate with db and other services on its own default network.\nThe traefik.http.routers.proj.rule label configures Traefik to route HTTP traffic with the \u0026ldquo;proj.traefik.me\u0026rdquo; hostname to the container. The traffic.docker.network label is necessary because web is on two networks. Finally, we set traefik.http.services.proj.loadbalancer.server.port for completeness, just in case your container needs a different port mapping than the port it is set to expose, or if it exposes multiple ports.\nThere is one final piece of magic: the \u0026ldquo;traefik.me\u0026rdquo; hostname. What is that? You can read about it at http://traefik.me/. Essentially it is a DNS service that resolves to any IP address that you want, but by default it resolves \u0026lt;xxx\u0026gt;.traefik.me to 127.0.0.1. There are other services like this including https://sslip.io/ and https://nip.io/.\nNow, because we don\u0026rsquo;t need to define any ports at all, it is possible to take advantage of a newish compose feature and reinstate the ports in the original compose.yaml file for those developers who don\u0026rsquo;t want to set up Traefik for themselves. So our final configuration looks like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # compose.yaml services: db: image: \u0026#34;postgres\u0026#34; environment: POSTGRES_DB: \u0026#34;proj\u0026#34; POSTGRES_USER: \u0026#34;user\u0026#34; POSTGRES_PASSWORD: \u0026#34;pass\u0026#34; web: build: . depends_on: - \u0026#34;db\u0026#34; environment: DATABASE_URL: \u0026#34;postgres://user:pass@db/proj\u0026#34; ports: - \u0026#34;8000:80\u0026#34; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # compose.override.yaml (to be created by each developer) services: web: labels: - \u0026#34;traefik.http.routers.proj.rule=Host(`proj.traefik.me`)\u0026#34; - \u0026#34;traefik.http.services.proj.loadbalancer.server.port=8000\u0026#34; - \u0026#34;traefik.docker.network=traefik\u0026#34; networks: - default - traefik ports: !reset [] networks: traefik: external: true The !reset [] tag sets the ports back to empty; you can read about it here. Note that unfortunately it can\u0026rsquo;t be used to set new ports, only reset them to default (you would have to use two layers of override file to set new ports). The !reset tag requires a fairly recent version of docker compose, at least greater than 2.18.0.\nA final note: you can check that these overrides are working correctly by running docker compose config.\nConclusion By leveraging both the compose.override.yaml file and Traefik it\u0026rsquo;s easy to run multiple web projects on your development system at the same time and have easy to remember names to access them all. Each developer is free to run as many as they want and create their own easily-manageable configurations. Traefik and traefik.me can also be used to allow other developers on your network to easily access your local development instances with no DNS configuration required.\nIt\u0026rsquo;s a shame that\n","permalink":"https://georgek.github.io/blog/posts/multiple-web-projects-traefik/","summary":"Docker Compose is a brilliant tool for bringing up local development environments for web projects. But working with multiple projects can be a pain due to clashes. For example, all projects want to listen to port 80 (or perhaps one of the super common higher ones like 8000 etc.). This forces developers to only bring one project up at a time, or hack the compose files to change the port numbers.","title":"Working on Multiple Web Projects with Docker Compose and Traefik"},{"content":"I use the Unbound DNS resolver built in to pfSense. By default the resolver filters out any results that are private IP addresses. Normally this makes sense: no public domain should have a private address. But sometimes it does make sense. For example there are some useful services like sslip.io that will resolve to any IP address that you like. So 127.0.0.1.sslip.io resolves to to 127.0.0.1. This is can be useful for local development, especially when working with containers and reverse proxies and the like.\nTo allow Unbound to resolve these properly an extra configuration needs to be added. pfSense has no GUI config so this must be added under the custom options in the DNS resolver settings in pfSense. My options look like this:\n1 2 3 4 5 server: private-domain: \u0026#34;azmk8s.io\u0026#34; private-domain: \u0026#34;nip.io\u0026#34; private-domain: \u0026#34;sslip.io\u0026#34; private-domain: \u0026#34;traefik.me\u0026#34; ","permalink":"https://georgek.github.io/blog/posts/pfsense-unbound-private/","summary":"I use the Unbound DNS resolver built in to pfSense. By default the resolver filters out any results that are private IP addresses. Normally this makes sense: no public domain should have a private address. But sometimes it does make sense. For example there are some useful services like sslip.io that will resolve to any IP address that you like. So 127.0.0.1.sslip.io resolves to to 127.0.0.1. This is can be useful for local development, especially when working with containers and reverse proxies and the like.","title":"Resolving Private IP Addresses with pfSense DNS Resolver"},{"content":"Even after using Emacs for 15 years there\u0026rsquo;s still so much I can learn. I probably should have already known this, but there\u0026rsquo;s a first time for everything.\nIt\u0026rsquo;s rare that Emacs hangs. Exceedingly rare. Which is probably why I didn\u0026rsquo;t know how to deal with it. Today Emacs started hanging when trying to open files over a remote TRAMP session (SSH).\nThe most important key of all that everyone who uses Emacs knows is C-g. This is the universal \u0026ldquo;quit\u0026rdquo; key and it has the power to interrupt any long running processes. What I didn\u0026rsquo;t know about is M-x toggle-debug-on-quit. I\u0026rsquo;ve used toggle-debug-on-error extensively when programming Elisp (I even have it bound to a key in Elisp buffers). toggle-debug-on-quit is similar except the debugger is invoked when you C-g.\nWhile this is enabled, I was able to reproduce the hang, then press C-g. I could see that what was happening is ess-r-package-auto-activate was being called via after-change-major-mode-hook, this was in turn calling on TRAMP again to try to find an R package or something. I don\u0026rsquo;t regularly use ESS mode, so I simply disabled this behaviour with (setq ess-r-package-auto-activate nil).\ntoggle-debug-on-quit should be toggled off again aftewards, as quitting isn\u0026rsquo;t actually an error most of the time. Doom modeline handily displays an icon when it\u0026rsquo;s enabled, confirming that I\u0026rsquo;m the last person to know about this.\nSomething else interesting to consider here is packages can still affect Emacs performance even if you aren\u0026rsquo;t using them. I haven\u0026rsquo;t used R or ESS mode for years, but I\u0026rsquo;ve left them in my config because, why not? But these \u0026ldquo;dormant\u0026rdquo; packages can still be impacting performance and it might be worth auditing hooks like after-change-major-mode-hook to check for packages you don\u0026rsquo;t really need any more.\n","permalink":"https://georgek.github.io/blog/posts/emacs-hangs-debug/","summary":"Even after using Emacs for 15 years there\u0026rsquo;s still so much I can learn. I probably should have already known this, but there\u0026rsquo;s a first time for everything.\nIt\u0026rsquo;s rare that Emacs hangs. Exceedingly rare. Which is probably why I didn\u0026rsquo;t know how to deal with it. Today Emacs started hanging when trying to open files over a remote TRAMP session (SSH).\nThe most important key of all that everyone who uses Emacs knows is C-g.","title":"Why is Emacs Hanging?"},{"content":"This is a little trick I just applied and thought was cool enough to write down.\nLet\u0026rsquo;s say you want to replace a name that is used throughout a project. Due to various conventions/restrictions in use the name might appear in several forms like: MY_COOL_NAME, my-cool-name, my_cool_name etc.\nIn Emacs you can invoke regexp replace across an entire project by invoking project-query-replace-regexp, by default bound to C-x p r. This will first prompt for the regexp to search for, then what to replace it with.\nFor the search regexp we can put: my\\([_-]\\)cool\\1name.\nThis allows either underscore or hyphen as a separator. Notice we use \\1 as the second separator. This is a \u0026ldquo;backreference\u0026rdquo; and simply refers to whatever was captured in the first group, in this case \\([_-]\\).\nWe can then us the same backreference in the replacement, so we can put: new\\1name.\nAfter pressing enter again emacs will then cycle through every replacement in every file in the project allowing you to either apply it, with y or skip it, with n. If you wish to make the changes across an entire file unconditionally, press !. If you wish to skip an entire file, press N. You can also press ? to see the other options.\nNotice Emacs does what you (probably) want when it comes to case. We didn\u0026rsquo;t type the search in upper case, but it will match MY_COOL_NAME and replace it with NEW_NAME. Similarly, if there were a My-Cool-Name, it would replace it with New-Name automatically.\n","permalink":"https://georgek.github.io/blog/posts/emacs-regexp-replace/","summary":"This is a little trick I just applied and thought was cool enough to write down.\nLet\u0026rsquo;s say you want to replace a name that is used throughout a project. Due to various conventions/restrictions in use the name might appear in several forms like: MY_COOL_NAME, my-cool-name, my_cool_name etc.\nIn Emacs you can invoke regexp replace across an entire project by invoking project-query-replace-regexp, by default bound to C-x p r. This will first prompt for the regexp to search for, then what to replace it with.","title":"Replacing Strings in an Entire Project"},{"content":"I\u0026rsquo;ve been using Emacs for almost 15 years now. Somewhat surprisingly, I hadn\u0026rsquo;t touched my config in three years! It\u0026rsquo;s been working that well. But now that Emacs 29 has been released I\u0026rsquo;ve decided to take a look at what\u0026rsquo;s new and there have been some big changes, particularly for Python.\nGoodbye Elpy, Goodbye Projectile Elpy has been the primary mode for Python development for me for years now. But sadly, it looks like the project is no more. The good news is there are better ways to do what it did. It\u0026rsquo;s bittersweet to say goodbye to it and I will be eternally grateful to the authors, but progress is progress.\nSimilarly, Projectile was what I used to manage projects. But now Emacs has project.el built in and I\u0026rsquo;ve opted to use that instead. One nice thing about project.el is it uses other standard stuff underneath like xref. I configured xref to use Ripgrep and now the Project commands like C-x p g use Ripgrep:\n1 2 3 (use-package xref :config (setq xref-search-program \u0026#39;ripgrep)) Native builds and tree-sitter I always build Emacs myself from source if I can. I run Gentoo on my personal computer so that goes without saying, but I do it on Ubuntu too, if only to get the latest versions. This does mean I can easily enable a couple of new features: native builds and tree-sitter.\nOn Gentoo this was a simple as adding a couple of USE flags to portage. My USE flags for emacs now look like:\napp-editors/emacs athena cairo gui gtk harfbuzz json libxml2 source tree-sitter jit -X The gtk -X also implies a pgtk build which is nice because I use wayland (sway).\nOn Ubuntu (20.04, yeah, old, this is one reason I prefer rolling distros) it was more difficult. I first pulled the source code (emacs-29.1.tar.gz) from a nearby GNU mirror per the GNU website. Then a few packages are required (I use i3/X11 on Ubuntu):\n1 2 3 4 sudo apt install autoconf make gcc texinfo libgtk-3-dev libxpm-dev libjpeg-dev \\ libgif-dev libtiff5-dev libgnutls28-dev libncurses5-dev libjansson-dev \\ libharfbuzz-dev libharfbuzz-bin imagemagick libmagickwand-dev libgccjit-10-dev \\ libgccjit0 gcc-10 libjansson4 libjansson-dev xaw3dg-dev texinfo libx11-dev Now, because libgccjit (required for native builds) is only for GCC 10, the build process has to be configured for GCC 10 specifically, in addition to enabling all the wanted features:\n1 2 3 4 5 CC=\u0026#34;gcc-10\u0026#34; ./configure --prefix=$HOME --with-json --with-native-compilation=aot \\ --with-modules --with-compress-install --with-threads --with-included-regex \\ --with-x-toolkit=lucid --with-zlib --with-jpeg --with-png --with-imagemagick \\ --with-tiff --with-xpm --with-gnutls --with-xft --with-xml2 --with-mailutils \\ --with-tree-sitter Note that I keep my own builds in $HOME by setting --prefix. By default the installation would put it in the system directories which I prefer not to do as those are controlled by my system package manager. Also note that I set --with-native-compilation=aot which makes native builds ahead of time instead of JIT compiling them. Run ./configure --help to see all of the build options.\nThen I just compiled it:\n1 make -j 8 # 8 threads The build can be tested with src/emacs -Q then, if it works:\n1 make install Eglot Elpy provided a proper IDE experience for Python but it did it in a completely custom, albeit very clever, way via a special RPC process which used jedi. Now with LSP we can get essentially the same sort of thing but in a more standard way that works with all languages.\nI have tried LSP (in particular, lsp-mode) in emacs before, but I wasn\u0026rsquo;t impressed. I cannot stand latency and the moment I detect latency when merely typing in a text editor, I walk away. But I\u0026rsquo;m pleased to say that with Emacs 29, native builds, Eglot and python-lsp-server it is now fast enough for me. lsp-mode might very well be fast enough now too. I\u0026rsquo;ll probably try it eventually.\nI installed python-lsp-server (with pipx on Ubuntu). This is my preferred way of installing Python apps if they\u0026rsquo;re not available in the base distro. Notice how there will be only one LSP server installed for my whole system (not one per virtualenv).\nEnabling Eglot is easy. To make it work for Python it just needs the following:\n1 2 (use-package eglot :hook (python-mode . eglot-ensure)) Now just open a Python file and it should work. It does everything Elpy did (or, at least, what I used it for) and more. Just like that.\nBy default, Eglot uses Flymake. I had previously been using Flycheck. I can\u0026rsquo;t really remember why, to be honest, so I\u0026rsquo;ll try using Flymake instead and say goodbye to Flycheck for now too.\nVirtualenvs OK, so, it doesn\u0026rsquo;t completely just work. One of the most important things for me is being able to jump to the definition of a symbol in the source. This does just work for first party stuff and (kinda) for standard library stuff, but it won\u0026rsquo;t work for third party stuff. That\u0026rsquo;s because the LSP server does know where to find those libraries.\nUsually when developing on a Python project one would create a virtual environment for it. I make everything a package such that doing a pip install -e . installs the package and all of its dependencies into the virtualenv. Then you just need to make the LSP server aware of this environment.\nI used to use virtualenvwrapper to create virtualenvs for each project, but I\u0026rsquo;ve found a better way: direnv. This allows you to create .envrc files in directories with anything you want in it then automatically loads it into your environment when you change to that directory. What\u0026rsquo;s even neater is it has built-in support for Python (and other languages).\nTo install direnv on Gentoo I used the Guru overlay:\n1 eselect repository enable guru After installing and setting up direnv, make a file called .envrc at the top of your project and put the following:\n1 layout python That\u0026rsquo;s it! After enabling your project for direnv support it will automatically create a virtualenv and activate it. When you change directory, it will deactivate it. Amazing!\nIn Emacs you can install the direnv package and enable it:\n1 2 3 (use-package direnv :config (direnv-mode)) Now when you browse to a project with a .envrc file it will just work.\nTree-sitter Finally, to enable tree-sitter I needed to first install the grammar for Python, I added the following to my emacs config:\n1 2 (setq treesit-language-source-alist \u0026#39;((python \u0026#34;https://github.com/tree-sitter/tree-sitter-python\u0026#34;))) And then (after evaling the above) you can run: M-x treesit-install-language-grammar. This builds the grammar for you and puts it in your emacs config.\nNow you can use the mode python-ts-mode instead of python-mode:\n1 2 3 4 (use-package python :mode (\u0026#34;\\\\.py\\\\\u0026#39;\u0026#34; . python-ts-mode) :init (add-to-list \u0026#39;major-mode-remap-alist \u0026#39;(python-mode . python-ts-mode))) The major-mode-remap-list entry means python-ts-mode will be used whenever python-mode would have been used, like when opening a script with no file extension but a Python shebang.\nCompletion One thing I cannot do without is some kind of completion capability. In bash I use tab-completion extensively and I consider any keyboard-driven software that doesn\u0026rsquo;t support at least tab-completion to be defective.\nBasic completion is supported in Emacs out of the box but it can be extended to be quite sophisticated. But I\u0026rsquo;ve always found it a bit overwhelming. My life was changed when I first enabled ido. The combination of completion and narrowing is amazing. Later I switched to other packages like ivy, Helm and Selectrum and enabled in-buffer completion with Company. Selectrum is now defunct and replaced with Vertico.\nFor the first time, I have a completion set up that I understand and that I\u0026rsquo;m very happy with.\nWhat I really wanted was fuzzy-style completion in minibuffer contexts but dead basic prefix-style completion within buffers. I also want the completion within-buffer to be driven by the tab key like in a bash shell. I\u0026rsquo;ve settled on Company within-buffer and Vertico in the minibuffer.\nI like the setting (setq tab-always-indent 'complete) which causes TAB to indent first, then complete, but I was getting weird behaviour where that completion would not launch company. So instead:\n1 (global-set-key (kbd \u0026#34;TAB\u0026#34;) #\u0026#39;company-indent-or-complete-common) This now does the right thing but launches Company instead of the default completion function.\nThe other major part is completion styles. I like the Orderless style for the fuzzy minibuffer style, but it doesn\u0026rsquo;t work for basic completion. Emacs supports setting a list of completion styles by setting completion-styles and further refining that for specific categories by setting completion-category-overrides. The trouble is, the category names for the latter are quite hard to find. But eventually I settled on the following configuration:\n1 2 3 4 5 6 7 (use-package orderless :init (setq completion-styles \u0026#39;(basic partial-completion orderless) completion-category-defaults nil completion-category-overrides \u0026#39;((project-file (styles orderless)) (buffer (styles orderless)) (command (styles orderless))))) This sets basic and partial-completion styles first by default everywhere. Company doesn\u0026rsquo;t really support the Orderless style, which is fine by me as I don\u0026rsquo;t want it in-buffer anyway. I then override it for particular categories to add orderless to the front. project-file is for finding files in projects with C-x p f, buffer is for switching buffers and command is for running commands with M-x.\nConclusion To sum up, I\u0026rsquo;ve switched from Projectile to project.el, from Elpy to Eglot/LSP and from virtualenvwrapper to direnv as well as including the latest improvements like native builds and tree-sitter. This has really simplified my config and I seem to have a renewed love for Emacs.\nI\u0026rsquo;ve been using this configuration for a few days now for real work and I really love it so far. Things like the eldoc and xref jump to definition features are working perfectly now and I\u0026rsquo;ve had real trouble with consistent behaviour before.\nMy actual emacs config does include a number of extra tweaks to all of this stuff. I love reading other people\u0026rsquo;s .emacs files, so maybe you\u0026rsquo;ll enjoy reading mine too: https://github.com/georgek/dot-emacs\nHappy hacking!\n","permalink":"https://georgek.github.io/blog/posts/emacs-python-2023/","summary":"I\u0026rsquo;ve been using Emacs for almost 15 years now. Somewhat surprisingly, I hadn\u0026rsquo;t touched my config in three years! It\u0026rsquo;s been working that well. But now that Emacs 29 has been released I\u0026rsquo;ve decided to take a look at what\u0026rsquo;s new and there have been some big changes, particularly for Python.\nGoodbye Elpy, Goodbye Projectile Elpy has been the primary mode for Python development for me for years now. But sadly, it looks like the project is no more.","title":"My 2023 Emacs Python Setup"},{"content":"On Linux, software should generally be installed with your system package manager (apt, yum, portage etc.) However, Calibre is a bit \u0026ldquo;special\u0026rdquo; in this respect. While well-loved, it\u0026rsquo;s known to be a bit difficult to package (to say the least) and most distro packages you\u0026rsquo;ll find are out of date. The official website recommends against using any distro packages and instead installing it directly from the site.\nUnfortunately, the official instructions are problematic for a number of reasons. For a start, copying and pasting commands from the browser is considered dangerous. But that\u0026rsquo;s easy to fix, in bash do Ctrl-X Ctrl-E and your preferred text editor will be opened for you to type your command. This means you can inspect what is pasted before is run (save the file then exit the editor to run the command). Very important. Always do this when copy/pasting from the web.\nBut that\u0026rsquo;s not all, it also has you run the installer as root. The installer does tuck everything nicely away inside /opt/calibre, but it\u0026rsquo;s just not a good idea for many reasons.\nUser-level installation Instead you can install it in your home directory under ~/opt like this:\n1 2 wget -nv -O- https://download.calibre-ebook.com/linux-installer.sh \\ | sh /dev/stdin install_dir=~/opt isolated=True Or, even better, as a completely different user so any error in the script can\u0026rsquo;t trample anything in your home directory:\n1 2 3 4 sudo useradd calibre # add new user the first time wget -nv -O- https://download.calibre-ebook.com/linux-installer.sh \\ | sudo -u calibre sh -s install_dir=~calibre/opt isolated=True Once finished it will tell you to run /home/\u0026lt;user\u0026gt;/opt/calibre/calibre to start. If you have ~/bin (or perhaps ~/.local/bin) on your PATH you can add a nicer link with the following:\n1 ln -s /home/\u0026lt;user\u0026gt;/opt/calibre/calibre ~/bin Then you should be able to run simply calibre.\nDesktop environment integration If you need a menu item in a desktop environment then you might first need to add the link to /usr/bin (this also makes it available for all users):\n1 sudo ln -s /home/calibre/opt/calibre/calibre /usr/bin/calibre Then you need to make a desktop file called /usr/share/applications/calibre-gui.desktop with the following:\n1 2 3 4 5 6 7 8 9 10 11 12 [Desktop Entry] Version=1.0 Type=Application Name=calibre GenericName=E-book library management Comment=E-book library management: Convert, view, share, catalogue all your e-books TryExec=calibre Exec=calibre --detach %U Icon=calibre-gui Categories=Office; X-GNOME-UsesNotifications=true MimeType=image/vnd.djvu;application/x-cb7;application/oebps-package+xml;application/epub+zip;application/x-mobi8-ebook;text/plain;application/x-cbc;application/xhtml+xml;application/x-cbz;application/ereader;application/pdf;text/fb2+xml;application/x-mobipocket-subscription;application/x-cbr;application/x-sony-bbeb;text/x-markdown;text/html;application/vnd.oasis.opendocument.text;application/x-mobipocket-ebook;application/vnd.ms-word.document.macroenabled.12;application/vnd.openxmlformats-officedocument.wordprocessingml.document;text/rtf;x-scheme-handler/calibre; You only need to make these links and desktop entry once. Next time you update Calibre they will point to the new version.\n","permalink":"https://georgek.github.io/blog/posts/calibre-rootless-install/","summary":"On Linux, software should generally be installed with your system package manager (apt, yum, portage etc.) However, Calibre is a bit \u0026ldquo;special\u0026rdquo; in this respect. While well-loved, it\u0026rsquo;s known to be a bit difficult to package (to say the least) and most distro packages you\u0026rsquo;ll find are out of date. The official website recommends against using any distro packages and instead installing it directly from the site.\nUnfortunately, the official instructions are problematic for a number of reasons.","title":"Install Calibre without Root"},{"content":"I cook a lot of food from scratch and it occurred to me one day that the way I understand and assimilate recipes is very similar to how make works.\nSo, in case you don\u0026rsquo;t know, make is a tool used to build executable software from source code. Building software often involves several steps such as translation, compilation, linking and bundling. The process required for a particular project is describe in a Makefile but, here\u0026rsquo;s the thing, it isn\u0026rsquo;t described imperatively, it\u0026rsquo;s described declaratively.\nLet\u0026rsquo;s look at an example:\n1 2 myprogram: code.c gcc code.c -o myprogram In the example myprogram is a target and code.c is a prerequisite. The target is what make is going to, well, make. The prerequisite is what is required before we can make it. In this case, the prerequisite is source code, so is always present and satisfied.\nThe second line tells make how to make the target from the prerequisite (OK, this bit is imperative, but we have to do something). In this case, we run a C compiler.\nIn this second example, more than one step is required to build the target:\n1 2 3 4 5 myprogram: module.o gcc module.o -o myprogram module.o: module.c gcc -c module.c -o module.o Now we first require module.o and, in case it\u0026rsquo;s not already present, we show how to make module.o too which requires module.c, the source code.\nMaking food So what does a food recipe look like in a Makefile? Here\u0026rsquo;s how to make a basic béchamel sauce:\n1 2 3 4 5 béchamel: milk roux Gradually incorporate milk into roux, whisking continuously roux: butter flour Combine equal parts melted butter and flour into smooth paste We could easily extend this file to include higher-level targets, like a Mornay sauce:\n1 2 mornay: béchamel grated-cheese Add grated cheese to warm sauce More complex recipes are then natural:\n1 2 3 4 5 cauliflower-cheese: mornay boiled-cauliflower Combine sauce and boiled cauliflower boilded-cauliflower: cauliflower Separate cauliflower and boil in salted water Implicit rules A perhaps lesser-known feature of make is that it contains implicit rules. That is, make already knows how to make some things, mostly around C compilation. These aren\u0026rsquo;t as often used today, probably because C is no longer the only language in town.\n1 module: module.o This is a valid Makefile. This works because make already knows how to make module.o from module.c and module from module.o.\nIt\u0026rsquo;s the same in the kitchen.\n1 salsa: chopped-tomato chopped-onion chopped-chilli Some things don\u0026rsquo;t need to be written as rules. Even if you\u0026rsquo;ve never seen a chilli before, you already know to get chopped chilli from chilli: you chop it with a knife. And you already know that to make a sauce from chopped ingredients: you mix them.\nParallel execution It\u0026rsquo;s possible to configure make to run jobs in parallel with the -j flag, for example -j4 says run up to four things at once, presumably because you have four CPU cores available. The following process can be sped up on two cores:\n1 myprogram: main.o module.o This is because building main.o and module.o don\u0026rsquo;t depend on each other so can each be built immediately, as soon as a CPU core is available.\nIt\u0026rsquo;s the same in the kitchen. Instead of CPU cores you have burners, ovens, toasters etc. The following can be executed in parallel given one toaster and one hob:\n1 beans-on-toast: warm-beans toasted-bread Cooking isn\u0026rsquo;t a script Before I could cook myself, I used to marvel at the ability of experienced cooks to not only reproduce a dish from memory, but to seemingly make it up as they went along. To observe it would appear the script was different every time, but the result was always the same!\nNow I realise how it\u0026rsquo;s possible: they weren\u0026rsquo;t memorising scripts. That would be far too hard. Imagine the hundreds of recipes and thousands of steps that would need to be remembered. Instead, human minds have a remarkable ability to organise this stuff, and I think it looks like one giant Makefile. We develop implicit rules far more comprehensive than those of make. Complex recipes are integrated by taking advantage of the redundancy in multiple layers of existing rules.\nWe probably even have a default target or, in English, a favourite comfort dish.\nWhen reading recipes they are almost always written in imperative style. My approach is to read it once through and assimilate it into my global Makefile before executing it. I don\u0026rsquo;t think it\u0026rsquo;s a good idea to execute any recipe from top to bottom without reading it first. I\u0026rsquo;ll often scribble down a recipe into a pseudo-Makefile format and take that into the kitchen rather than the original text.\nFor the record, I don\u0026rsquo;t actually write down recipes in anything close to a strict Makefile format but, just for fun, here\u0026rsquo;s what I think a Margherita pizza recipe looks like:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 margherita-pizza: cooked-margherita-pizza basil Add basil to top of pizza cooked-margherita-pizza: pizza-base tomato-sauce cheese Spread sauce on base and top with cheese, bake in oven pizza-base: pizza-dough Stretch dough into thin circular disc pizza-dough: flour water salt yeast Combine ingredients, knead, prove for many hours tomato-sauce: tomato Peel and chop tomatoes ","permalink":"https://georgek.github.io/blog/posts/cooking-with-make/","summary":"In which I compare cooking food with building software","title":"Cooking with Make"},{"content":"If you want to start Arduino programming you\u0026rsquo;ll notice a lot of the documentation and tutorials are centred around the Arduino IDE. Now, obviously, as an Emacs user you\u0026rsquo;ll be loath to install something like Arduino IDE, let alone actually use it. The good news is it\u0026rsquo;s super easy to get started with Arduino with any editor, including Emacs and even Vim if you so desire.\nAll the Arduino IDE is doing is calling a cross-compiler toolchain then using avrdude to communicate with the Arduino to upload software. The Arduino Uno and Nano both use the Atmel AVR platform so what you need is a toolchain that can target that platform. Now, you could install your own toolchain and call avrdude directly. If you know how to do that then I guess you can stop reading now. But if you don\u0026rsquo;t, or aren\u0026rsquo;t interested in learning how (it\u0026rsquo;s not very interesting), then read on.\nPlatformIO PlatformIO is a project that makes it really easy to do embedded development.\nFirst, install PlatformIO, I like to use pipx to install tools like this: pipx install platformio.\nNow, start your project by making a directory for it:\n1 2 mkdir my_new_project cd my_new_project And initialise a PlatformIO project:\n1 platformio project init --board uno --board nanoatmega328 This will configure your project for both Arduino Uno and Nano.\nNow write some barebones C++ code that does nothing in src/main.cpp:\n1 2 3 4 5 6 7 8 9 10 11 #include \u0026#34;Arduino.h\u0026#34; void setup() { // your setup code here } void loop() { // your main loop here } This is, of course, totally standard C++ so you can use your normal C++ modes etc.\nYou should end up with a project structure like this:\n1 2 3 4 5 6 7 8 9 10 . ├── include │ └── README ├── lib │ └── README ├── platformio.ini ├── src │ └── main.cpp └── test └── README Now you can simply run the following to build the software for all platforms specified in platformio.ini:\n1 platformio run To build and upload the software to your Arduino, if you are on Linux you first have to install some udev rules: https://docs.platformio.org/en/latest/core/installation/udev-rules.html\nThen you can run simply:\n1 2 platformio run -e nanoatmega328 -t upload # for arduino nano platformio run -e uni -t upload # for arduino uno This tends to cleverly pick the right serial device but if you have more than one you might need to specify it with --upload-port.\nYou can adapt these as your command for M-x compile or write a Makefile if you prefer. Don\u0026rsquo;t forget it expects to be run from the top-level where platformio.ini lives, though.\nAnother super-useful command to be aware of is platformio device monitor. This gives you a serial terminal for communicating with your device. Really convenient. There\u0026rsquo;s a lot more too.\nAnd that\u0026rsquo;s it! You\u0026rsquo;ll find the Arduino documentation here: https://www.arduino.cc/reference/en/ That\u0026rsquo;s all you should need to get started. Happy hacking!\n","permalink":"https://georgek.github.io/blog/posts/emacs-arduino/","summary":"If you want to start Arduino programming you\u0026rsquo;ll notice a lot of the documentation and tutorials are centred around the Arduino IDE. Now, obviously, as an Emacs user you\u0026rsquo;ll be loath to install something like Arduino IDE, let alone actually use it. The good news is it\u0026rsquo;s super easy to get started with Arduino with any editor, including Emacs and even Vim if you so desire.\nAll the Arduino IDE is doing is calling a cross-compiler toolchain then using avrdude to communicate with the Arduino to upload software.","title":"Arduino Programming with Emacs"},{"content":"I love going to the cinema, but I\u0026rsquo;ve always been disappointed that I can\u0026rsquo;t see older films and I can\u0026rsquo;t see them when it\u0026rsquo;s convenient for me. There have always been ways to watch films at home, but even today when large screens and high-definition formats are ubiquitous, it\u0026rsquo;s just not the same as the cinema experience. There\u0026rsquo;s something completely different about the big screen that a TV in a living room can\u0026rsquo;t replicate. For that reason I\u0026rsquo;ve wanted my own home cinema for as long as I can remember. The problem is I don\u0026rsquo;t want to spend a lot of money on it.\nThe first iteration of my home cinema looked like this:\nHome cinema has a strong overlap with the audiophile world. You can spend as much as you want on it, and there will always be more. It\u0026rsquo;s not that it\u0026rsquo;s wrong to spend a lot on it; there are real benefits to the latest, high-end gear. But I think you can get 90% of the way there on about 10% of the budget, if that. However, you might have to make lifestyle sacrifices to save the most money.\nThis is my definition of a home cinema system. It will be opinionated and I make no apologies for that. You can do things differently, but I think the following features are non-negotiable:\nBig screen, at least 100\u0026quot; diagonal, filling your field of view, Full dynamic range, high quality audio, Highest quality media (usually blu-ray), Locally available; no streaming, Dark room. A note before starting: this will also take some dedication. It\u0026rsquo;s a real project. Saving money usually means building your own knowledge rather than paying for someone else\u0026rsquo;s. But if you can get there, the results are thoroughly rewarding.\nProjector Currently I think a projector is the only option. You can get TVs up to 75\u0026quot; or so, but that\u0026rsquo;s not big enough and they are so unwieldy at that size you might as well get a projector.\nThe best home cinema projectors are the JVC DLA series. If you can stretch to a second hand X500 or newer, it will be great. The best value projectors are DLP projectors from makes like Epson, JVC or Panasonic. They are not as good as the JVC DLA projectors, and suffer from \u0026ldquo;colour wheel\u0026rdquo; artifacts, but many people enjoy them. Do not consider cheap Chinese projectors on Amazon. They are rubbish. Buy second hand from a good make.\nBe aware that projector bulbs have a finite life and are expensive. If buying second hand the seller should tell you the number of hours left on the bulb. Factor in the cost of a new bulb if you\u0026rsquo;re not sure. JVC bulbs can cost £300 new so really not cheap.\nYou need a screen. Don\u0026rsquo;t project on to the wall. The screen is really important, but you can start with a cheap Chinese one from Ebay. I used a screen on a tripod because it didn\u0026rsquo;t need to be installed. But better ones will need to be attached to a wall.\nYou don\u0026rsquo;t need 4K, you don\u0026rsquo;t need HDR, you don\u0026rsquo;t need high frame rate. A high quality 1080p projector at 24fps on a 120\u0026quot; screen is more than enough. Luckily this also means you don\u0026rsquo;t have to worry about any HDMI standards etc. You can just buy whatever is cheapest.\nThe Room Possibly the most important part of all of this is the room. First thing to get out of the way: a home cinema is not a living room. You won\u0026rsquo;t just be able to plonk your system down in the living room and call it a day. This is where the real project is. The rest is just buying equipment.\nThe ideal room is a squarish box shape with no windows. If you do have windows, chimney breasts, an L-shaped room etc. then it will make this more difficult, but you have to work with what you have. I wouldn\u0026rsquo;t suggest acquiring a new space in a budget home cinema guide.\nIf you do need your room to double up as a living room then you need to consider ways to convert it between these two very different purposes. This is especially true if live in a household that doesn\u0026rsquo;t completely share your enthusiasm for the project.\nFurniture can be just standard living room furniture. A sofa is ideal. It just needs to be comfortable and oriented towards the screen.\nLight control is extremely important for a projector to reach its potential. You need to block out external light sources but you also need to \u0026ldquo;deaden\u0026rdquo; the room as the projector itself will cause ambient light in the room which will kill your contrast. If you have windows, blackout curtains are a must. I bought full-length black blackout curtains and attached them to the walls near the screen. You can \u0026ldquo;open\u0026rdquo; the curtains if you want to convert the room back into a living room. A white ceiling is a disadvantage. Ideally it would be black. But you can get away with just having blacked-out walls.\nSound Good sound is just as important as a big screen. What matters is good quality speakers and amplifier and correct positioning of those speakers. Do not consider anything with Atmos or all-in-one kits that contain a handful of tiny little speakers. Your budget home cinema uses good old Dolby Digital and is at most a 5.1 set up. Your equipment will be mostly second hand.\nYou will upgrade your equipment in the following order:\nStereo set up Start with a high quality stereo system. You want speakers that can handle down to about 60Hz or lower, if possible, and a stereo amplifier.\nAn amplifier with 30W per channel should be fine (higher is better, but no point going above 80W per channel). Look for Japanese brands like Pioneer, Marantz, Denon, Sony or Technics. Basic amps last for decades and are readily available for very little money. As an example I bought a Pioneer A300X for about £50 without even trying to find a good deal.\nBookshelf speakers are cheapest but you need to position them at around ear height somehow. A couple of pieces of furniture are fine. Make sure you get hi-fi speakers, not PA or monitor speakers. Look up the frequency response and make sure it goes down to around 60Hz. Note that generally more capable speakers are physically larger and heavier.\nYou need to position them correctly. Basically you want a triangle with the speakers in front and you in the middle. Even a basic stereo system should sound a lot better than any TV.\nEnvironment The environment needs to be quiet. You don\u0026rsquo;t want any sources of noise. You also want to be able to play sound loudly without fear of annoying neighbours etc. This is so you can enjoy sound with full dynamic range.\nSubwoofer Next you can add a subwoofer. A good quality one from a make like SVS is worth it, but they do hold their value pretty well, so you might need to allocate more funds then your whole stereo set up. Make sure the subwoofer supports both high level and low level inputs. The low level input is preferable, but you need an AVR for that, so for now you will use the high level set up.\nAVR An AVR is a more advanced amp that will support multi-channel audio and digital inputs. You can also plug your subwoofer in with the low level input which you definitely should. These don\u0026rsquo;t hold their value well and as long as you get one without the latest HDMI standard you can get one for 10% of its original value.\nMore speakers If you get this far, you should first look into adding a centre speaker. But you really want it to match your front stereo speakers, so you might want to upgrade the whole set of front speakers to matched set, called an LCR (left, centre, right). However, note that the optimal position for the centre speakers is behind the screen and this suddenly starts to cost a lot more money.\nAfter that you can consider surround speakers, but these don\u0026rsquo;t add that much so do not consider them before doing the above. You can, however, consider them before a centre speaker if you are the only one using the cinema, as the ghost centre of the stereo set up should be good enough.\nMedia I use a NAS to store my media. You can find an excellent video series by Jeff Geerling outlining how to rip blu-ray media to a NAS, starting here: https://www.youtube.com/watch?v=RZ8ijmy3qPo\nYou\u0026rsquo;ll want to keep the NAS outside of your cinema as it will probably have spinning media and be noisy.\nI use Kodi on a Raspberry Pi in my cinema to play back the content from the NAS. If you don\u0026rsquo;t have an AVR yet, you will need a USB analogue sound adaptor for it. I recommend the Behringer UCA202 which can be had new for around £20. If you do have an AVR then you don\u0026rsquo;t need this as you will use audio passthrough via HDMI, but at £20 this is probably cheaper to get started.\nConclusion If you stick to second hand stuff you can cobble together a great home cinema for less than £2000. It\u0026rsquo;s still a lot of money and takes a lot of work and research, but it\u0026rsquo;s a great project. If a partner exists, it helps a lot if they are understanding and have a similar frugal mindset. If you want this to look good in your living room, expect to pay many times more and put in a lot more work. Hopefully you don\u0026rsquo;t have to. Enjoy your home cinema journey!\n","permalink":"https://georgek.github.io/blog/posts/shoestring-home-cinema/","summary":"I love going to the cinema, but I\u0026rsquo;ve always been disappointed that I can\u0026rsquo;t see older films and I can\u0026rsquo;t see them when it\u0026rsquo;s convenient for me. There have always been ways to watch films at home, but even today when large screens and high-definition formats are ubiquitous, it\u0026rsquo;s just not the same as the cinema experience. There\u0026rsquo;s something completely different about the big screen that a TV in a living room can\u0026rsquo;t replicate.","title":"Building a Home Cinema on a Shoestring"},{"content":"I\u0026rsquo;ve always thought I should write a blog, but I just never got around to setting it up. I know there are services you can simply sign up to and start writing, but that isn\u0026rsquo;t for me. I have two requirements for this thing:\nI can write using tools of my choice, I can host it anywhere. My tool of choice for writing anything is emacs and, for natural language in particular, org-mode. This is a bit like markdown, but better. For version control and deployment I use git.\nI also want to be able to host it anywhere because I don\u0026rsquo;t want to be tied to a host and, ideally, I don\u0026rsquo;t want to pay for it either. Back in the day it was common to use a dynamic site for a blog. Your content would live in a database and was served up using some backend process like WordPress. But that\u0026rsquo;s too expensive and places too many requirements on the host.\nWith that in mind, I\u0026rsquo;ve decided to use a static site generator. This is ideal as it means I don\u0026rsquo;t have to write raw HTML myself (although you can) but the output can be hosted anywhere. I\u0026rsquo;ve decided to use Hugo simply because it looks good, seems fast, well maintained, supports the workflow I want and, most importantly, supports org-mode.\nUsing org-mode with Hugo First of all, you set up your Hugo project by following the quickstart guide.\nThe next thing I did was install the PaperMod theme, as it seems like a decent default for a blog.\nNow, to start a new page using org-mode, you first need to install an archetype. These are essentially templates that Hugo uses to start new content. By default it comes with a markdown archetype in archetypes/default.md. You should add the following code in archetypes/default.org:\n1 2 3 4 5 6 7 8 9 #+TITLE: {{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }} #+DATE: {{ .Date }} #+DRAFT: true #+DESCRIPTION: #+CATEGORIES[]: #+TAGS[]: #+KEYWORDS[]: #+SLUG: #+SUMMARY: Now you can start a new org-mode post by running: hugo new posts/my-org-post.org. You\u0026rsquo;ll find your org-mode file ready to edit in content/posts/my-org-post.org. The metadata is pretty self-explanatory, but you can just play around with it.\nDeploying with Github Actions First of all, before you build or commit anything, add a .gitignore file:\n/.hugo_build.lock /public/* !/public/.nojekyll This will ensure you don\u0026rsquo;t accidentally commit your locally built version of the site.\nYou should also add the .nojekyll file to stop GitHub trying to run Jekyll (another static site generator) on your stuff. I\u0026rsquo;m not sure if this is still necessary but it can\u0026rsquo;t harm:\n1 2 mkdir -p public touch public/.nojekyll Now commit the .gitignore and .nojekyll files.\nTo publish your site you simply run hugo. This builds the site, including all articles that are not marked as draft, and puts it all into the /public/ directory. Now, you could simply copy the contents of that directory to a web server of your choice. That\u0026rsquo;s how we did it back in the day. This is how it meets my \u0026ldquo;can host anywhere\u0026rdquo; requirement.\nBut I\u0026rsquo;m lazy and I want it to be easier. I just want the site to build and deploy when I push my changes to git. This is actually remarkably simple to achieve with modern CI tooling such as GitHub Actions. Although, note: I won\u0026rsquo;t be tied to GitHub or GitHub Actions in any meaningful way, it\u0026rsquo;s essentially a glorified copy at the end of the day and I can always build my site on my own computer and copy the output the \u0026ldquo;old-fashioned\u0026rdquo; way.\nTo build using GitHub simply add the following to /.github/workflows/hugo.yml:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 name: hugo on: push: branches: [master] permissions: contents: write jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.115.2\u0026#39; extended: true - name: Build run: hugo --minify - name: Deploy uses: JamesIves/github-pages-deploy-action@v4 with: branch: gh-pages folder: public This pipeline is triggered by pushes to the master branch. It checks out the code, sets up Hugo with the same version that I used locally, builds using --minify (I don\u0026rsquo;t like minified pages generally, but the source is available freely so might as well save bandwidth) and deploys it to the gh-pages branch. Note that the source will live on the master branch (or any other branch), the built version will end up on the gh-pages branch, which will then be deployed to Github Pages itself.\nConclusion This should be everything needed to get started writing a blog (or any static site) with Hugo and hosting it on Github. If you are reading this then I guess it worked!\nLinks to the tools in use:\norg-mode: https://orgmode.org/ Hugo: https://gohugo.io/ GitHub Pages: https://pages.github.com/ actions-hugo: https://github.com/peaceiris/actions-hugo github-pages-deploy-action: https://github.com/JamesIves/github-pages-deploy-action Addendum Now that I\u0026rsquo;ve written a few posts I\u0026rsquo;ve found the built-in org support of Hugo pretty limiting. It doesn\u0026rsquo;t have first-class support like Markdown does. Thankfully there is the ox-hugo package which can export org-mode files to Markdown, before being read by Hugo.\nThe layout for the project is a bit different as it leverages org-mode to handle tags and categories in a nicer way, but it\u0026rsquo;s mostly the same (I didn\u0026rsquo;t really have to convert my existing posts, but I did anyway). The main difference is in how the project is built. The GitHub Actions pipeline contains one new entry to set up Emacs:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 name: deploy on: push permissions: contents: write jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true - name: Setup Emacs uses: purcell/setup-emacs@master with: version: 29.1 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.118.2\u0026#39; extended: true - name: Build run: make - name: Deploy uses: JamesIves/github-pages-deploy-action@v4 with: branch: gh-pages folder: public if: github.ref == \u0026#39;refs/heads/master\u0026#39; The build step is now container within a Makefile and looks like this:\n1 2 3 build: cd content-org \u0026amp;\u0026amp; emacs --batch -Q --load ../publish.el --funcall gpk-publish-all hugo --minify This runs Emacs in batch mode. The file publish.el contains settings and functions necessary for running ox-hugo:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 ;;; publish.el --- publish org-mode blog -*- lexical-binding: t; -*- ;;; Commentary: ;;; original influence: https://github.com/NethumL/nethuml.github.io/ ;;; Code: (defconst gpk-content-files \u0026#39;(\u0026#34;life.org\u0026#34; \u0026#34;networking.org\u0026#34; \u0026#34;programming.org\u0026#34; \u0026#34;software.org\u0026#34; \u0026#34;technology.org\u0026#34; \u0026#34;thoughts.org\u0026#34;)) ;; Install packages (require \u0026#39;package) (package-initialize) (unless package-archive-contents (add-to-list \u0026#39;package-archives \u0026#39;(\u0026#34;nongnu\u0026#34; . \u0026#34;https://elpa.nongnu.org/nongnu/\u0026#34;) t) (add-to-list \u0026#39;package-archives \u0026#39;(\u0026#34;melpa\u0026#34; . \u0026#34;https://melpa.org/packages/\u0026#34;) t) (package-refresh-contents)) (dolist (pkg \u0026#39;(org-contrib ox-hugo)) (package-install pkg)) (require \u0026#39;url-methods) (url-scheme-register-proxy \u0026#34;http\u0026#34;) (url-scheme-register-proxy \u0026#34;https\u0026#34;) (require \u0026#39;org) (require \u0026#39;ox-extra) (require \u0026#39;ox-hugo) (ox-extras-activate \u0026#39;(ignore-headlines)) (defun gpk-publish-all () \u0026#34;Publish all content files\u0026#34; (message \u0026#34;Publishing from emacs...\u0026#34;) (dolist (file gpk-content-files) (find-file file) (org-hugo-export-wim-to-md t) (message (format \u0026#34;Exported from %s\u0026#34; file))) (message \u0026#34;Finished exporting to markdown\u0026#34;)) ;;; publish.el ends here As you can see from the comment, this was \u0026ldquo;influenced\u0026rdquo; (ie. taken) from another blogger and can be found here.\n","permalink":"https://georgek.github.io/blog/posts/hugo-org-mode/","summary":"I\u0026rsquo;ve always thought I should write a blog, but I just never got around to setting it up. I know there are services you can simply sign up to and start writing, but that isn\u0026rsquo;t for me. I have two requirements for this thing:\nI can write using tools of my choice, I can host it anywhere. My tool of choice for writing anything is emacs and, for natural language in particular, org-mode.","title":"Writing a Blog with Org-mode"}]